{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import groq\n",
    "import os\n",
    "import json\n",
    "from groq import Groq\n",
    "from llama_index.core import SimpleDirectoryReader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "reader = SimpleDirectoryReader(input_dir=\".\")\n",
    "documents = reader.load_data()\n",
    "doc_dicts = [{\"content\": d.text, **d.metadata} for d in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'MIT License\\n\\nCopyright (c) 2024 Ajay Arasanipalai\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n',\n",
       "  'file_path': '/Users/iyaja/Git/llama-fs/LICENSE',\n",
       "  'file_name': 'LICENSE',\n",
       "  'file_size': 1074,\n",
       "  'creation_date': '2024-05-11',\n",
       "  'last_modified_date': '2024-05-11'},\n",
       " {'content': 'def get_doc_summaries(path: str) -> List[Dict[str, str]]:\\n\\n    [\\n        {\\n            filename: \\n            dir: \\n            meta: \\n            contents: \\n            summary: \\n        }\\n    ]\\n',\n",
       "  'file_path': '/Users/iyaja/Git/llama-fs/loader.py',\n",
       "  'file_name': 'loader.py',\n",
       "  'file_type': 'text/x-python',\n",
       "  'file_size': 196,\n",
       "  'creation_date': '2024-05-11',\n",
       "  'last_modified_date': '2024-05-11'},\n",
       " {'content': 'ollama\\nchromadb\\nllama-index\\nlitellm\\ngroq\\ndocx2txt',\n",
       "  'file_path': '/Users/iyaja/Git/llama-fs/requirements.txt',\n",
       "  'file_name': 'requirements.txt',\n",
       "  'file_type': 'text/plain',\n",
       "  'file_size': 49,\n",
       "  'creation_date': '2024-05-11',\n",
       "  'last_modified_date': '2024-05-11'},\n",
       " {'content': '\\n\\n\\nimport openai\\nimport groq\\nimport os\\nimport json\\nfrom groq import Groq\\nfrom llama_index.core import SimpleDirectoryReader\\n\\n\\n# ',\n",
       "  'file_path': '/Users/iyaja/Git/llama-fs/scratch.ipynb',\n",
       "  'file_name': 'scratch.ipynb',\n",
       "  'file_size': 7717,\n",
       "  'creation_date': '2024-05-11',\n",
       "  'last_modified_date': '2024-05-11'},\n",
       " {'content': '\\n\\n\\nos.environ[\"GROQ_API_KEY\"] = \"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\"\\n\\n\\n# # Summarize Files\\n# \\n\\n# ',\n",
       "  'file_path': '/Users/iyaja/Git/llama-fs/scratch.ipynb',\n",
       "  'file_name': 'scratch.ipynb',\n",
       "  'file_size': 7717,\n",
       "  'creation_date': '2024-05-11',\n",
       "  'last_modified_date': '2024-05-11'},\n",
       " {'content': '\\n\\n\\nreader = SimpleDirectoryReader(input_dir=\"path/to/directory\")\\ndocuments = reader.load_data()\\ndoc_dicts = [{\"content\": d.text, **d.metadata} for d in documents]\\n\\n\\n# In[ ]:\\n\\n\\ndoc_dicts\\n\\n\\n# In[ ]:\\n\\n\\nPROMPT = f\"\"\"\\nThe following is a list of file contents, along with their metadata. For each file, provide a summary of the contents.\\n\\n{doc_dicts}\\n\\nReturn a JSON list with the following schema:\\n\\n```json\\n{{\\n  \"files\": [\\n    {{\\n      \"filename\": \"name of the file\",\\n      \"summary\": \"summary of the content\"\\n    }}\\n  ]\\n}}\\n```\\n\"\"\".strip()\\n\\n\\n# In[ ]:\\n\\n\\nclient = Groq(\\n    api_key=os.environ.get(\"GROQ_API_KEY\"),\\n)\\n\\nchat_completion = client.chat.completions.create(\\n    messages=[\\n        {\\n            \"role\": \"system\",\\n            \"content\": \"Always return JSON. Do not include any other text or formatting characters.\",\\n        },\\n        {\\n            \"role\": \"user\",\\n            \"content\": PROMPT,\\n        },\\n    ],\\n    model=\"llama3-70b-8192\",\\n    response_format={\"type\": \"json_object\"},\\n)\\n\\nsummaries = json.loads(chat_completion.choices[0].message.content)[\"files\"]\\n\\n\\n# In[ ]:\\n\\n\\nsummaries\\n\\n\\n# # Create File Tree\\n# \\n\\n# In[ ]:\\n\\n\\nPROMPT = f\"\"\"\\nThe following is a list of files and a summary of their contents. Read them carefully, then propose a directory structure that optimally organizes the files using known conventions and best practices.\\n\\n{summaries}\\n\\nYou will solve this task by adding a `path` key to the JSON object below. The value of the `path` key should be the path to the file that you think is the most relevant to the summary.\\n\"\"\".strip()\\n\\n\\n# In[ ]:\\n\\n\\nclient = Groq(\\n    api_key=os.environ.get(\"GROQ_API_KEY\"),\\n)\\n\\nchat_completion = client.chat.completions.create(\\n    messages=[\\n        {\\n            \"role\": \"system\",\\n            \"content\": \"Always return JSON. Do not include any other text or formatting characters.\",\\n        },\\n        {\\n            \"role\": \"user\",\\n            \"content\": PROMPT,\\n        },\\n    ],\\n    model=\"llama3-70b-8192\",\\n    # response_format={\"type\": \"json_object\"},\\n)\\n\\nfile_tree = json.loads(chat_completion.choices[0].message.content)\\n\\n\\n# In[ ]:\\n\\n\\n\\n\\n\\n# In[ ]:\\n\\n\\n\\n\\n',\n",
       "  'file_path': '/Users/iyaja/Git/llama-fs/scratch.ipynb',\n",
       "  'file_name': 'scratch.ipynb',\n",
       "  'file_size': 7717,\n",
       "  'creation_date': '2024-05-11',\n",
       "  'last_modified_date': '2024-05-11'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "PROMPT = f\"\"\"\n",
    "The following is a list of file contents, along with their metadata. For each file, provide a summary of the contents.\n",
    "\n",
    "{doc_dicts}\n",
    "\n",
    "Return a JSON list with the following schema:\n",
    "\n",
    "```json\n",
    "{{\n",
    "  \"files\": [\n",
    "    {{\n",
    "      \"filename\": \"name of the file\",\n",
    "      \"summary\": \"summary of the content\"\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "```\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Always return JSON. Do not include any other text or formatting characters.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": PROMPT,\n",
    "        },\n",
    "    ],\n",
    "    model=\"llama3-70b-8192\",\n",
    "    response_format={\"type\": \"json_object\"},\n",
    ")\n",
    "\n",
    "summaries = json.loads(chat_completion.choices[0].message.content)[\"files\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'filename': 'LICENSE', 'summary': 'MIT license information'},\n",
       " {'filename': 'loader.py',\n",
       "  'summary': 'Function definition for getting document summaries'},\n",
       " {'filename': 'requirements.txt',\n",
       "  'summary': 'List of dependencies for the project'},\n",
       " {'filename': 'scratch.ipynb',\n",
       "  'summary': 'Code for interacting with LLaMA and Groq'},\n",
       " {'filename': 'scratch.ipynb',\n",
       "  'summary': 'Code for interacting with LLaMA and Groq'},\n",
       " {'filename': 'scratch.ipynb',\n",
       "  'summary': 'Code for interacting with LLaMA and Groq'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create File Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "PROMPT = f\"\"\"\n",
    "The following is a list of files and a summary of their contents. Read them carefully, then propose a directory structure that optimally organizes the files using known conventions and best practices.\n",
    "\n",
    "{summaries}\n",
    "\n",
    "You will solve this task by adding a `path` key to the JSON object below. The value of the `path` key should be the path to the file that you think is the most relevant to the summary.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Always return JSON. Do not include any other text or formatting characters.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": PROMPT,\n",
    "        },\n",
    "    ],\n",
    "    model=\"llama3-70b-8192\",\n",
    "    # response_format={\"type\": \"json_object\"},\n",
    ")\n",
    "\n",
    "file_tree = json.loads(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "BASE_DIR = pathlib.Path(\"test_dir\")\n",
    "BASE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "for file in file_tree:\n",
    "    file[\"path\"] = pathlib.Path(file[\"path\"])\n",
    "    # Create file in specified base directory\n",
    "    (BASE_DIR / file[\"path\"]).parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(BASE_DIR / file[\"path\"], \"w\") as f:\n",
    "        f.write(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
