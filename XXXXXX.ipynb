{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import groq\n",
    "import os\n",
    "import json\n",
    "from groq import Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MIT License\\n\\nCopyright (c) 2024 Ajay Arasanipalai\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n',\n",
       " {'file_path': '/Users/iyaja/Git/llama-fs/LICENSE',\n",
       "  'file_name': 'LICENSE',\n",
       "  'file_size': 1074,\n",
       "  'creation_date': '2024-05-11',\n",
       "  'last_modified_date': '2024-05-11'})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = documents[0]\n",
    "d.text, d.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "doc_dicts = [{\"content\": d.text, **d.metadata} for d in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'MIT License\\n\\nCopyright (c) 2024 Ajay Arasanipalai\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n',\n",
       "  'file_path': '/Users/iyaja/Git/llama-fs/LICENSE',\n",
       "  'file_name': 'LICENSE',\n",
       "  'file_size': 1074,\n",
       "  'creation_date': '2024-05-11',\n",
       "  'last_modified_date': '2024-05-11'},\n",
       " {'content': '\\n\\n\\nimport openai\\nimport groq\\nimport os\\n\\n\\n# In[ ]:\\n\\n\\nos.environ[\"GROQ_API_\"] = \"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\"\\n\\n\\n# ',\n",
       "  'file_path': '/Users/iyaja/Git/llama-fs/XXXXXX.ipynb',\n",
       "  'file_name': 'XXXXXX.ipynb',\n",
       "  'file_size': 117002,\n",
       "  'creation_date': '2024-05-11',\n",
       "  'last_modified_date': '2024-05-11'},\n",
       " {'content': '\\n\\n\\nfrom llama_index.core import SimpleDirectoryReader\\n\\nreader = SimpleDirectoryReader(input_dir=\"sample_data\")\\ndocuments = reader.load_data()\\n\\n\\n# ',\n",
       "  'file_path': '/Users/iyaja/Git/llama-fs/XXXXXX.ipynb',\n",
       "  'file_name': 'XXXXXX.ipynb',\n",
       "  'file_size': 117002,\n",
       "  'creation_date': '2024-05-11',\n",
       "  'last_modified_date': '2024-05-11'},\n",
       " {'content': '\\n\\n\\nPROMPT = \"\"\"\\nThe following is a list of files, their metadata, and contents. Read them and create a \\n\"\"\".strip()\\n\\n\\n# In[ ]:\\n\\n\\n{\\n    \"name\" : \\n    \"content_summary\": \\n    \"last_edited\": \\n}\\n\\njson.hu\\n\\n\\n# ',\n",
       "  'file_path': '/Users/iyaja/Git/llama-fs/XXXXXX.ipynb',\n",
       "  'file_name': 'XXXXXX.ipynb',\n",
       "  'file_size': 117002,\n",
       "  'creation_date': '2024-05-11',\n",
       "  'last_modified_date': '2024-05-11'},\n",
       " {'content': '\\n\\n\\ndocuments\\n\\n\\n# In[ ]:\\n\\n\\n\\n\\n',\n",
       "  'file_path': '/Users/iyaja/Git/llama-fs/XXXXXX.ipynb',\n",
       "  'file_name': 'XXXXXX.ipynb',\n",
       "  'file_size': 117002,\n",
       "  'creation_date': '2024-05-11',\n",
       "  'last_modified_date': '2024-05-11'},\n",
       " {'content': 'ollama\\nchromadb\\nllama-index\\nlitellm\\ngroq\\ndocx2txt',\n",
       "  'file_path': '/Users/iyaja/Git/llama-fs/requirements.txt',\n",
       "  'file_name': 'requirements.txt',\n",
       "  'file_type': 'text/plain',\n",
       "  'file_size': 49,\n",
       "  'creation_date': '2024-05-11',\n",
       "  'last_modified_date': '2024-05-11'}]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "PROMPT = f\"\"\"\n",
    "The following is a list of file contents, along with their metadata. For each file, provide a summary of the contents.\n",
    "\n",
    "{doc_dicts}\n",
    "\n",
    "Return a JSON list with the following schema:\n",
    "\n",
    "```json\n",
    "{{\n",
    "  \"files\": [\n",
    "    {{\n",
    "      \"name\": \"name of the file\",\n",
    "      \"summary\": \"summary of the content\"\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "```\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Always return JSON. Do not include any other text or formatting characters.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": PROMPT,\n",
    "        },\n",
    "    ],\n",
    "    model=\"llama3-70b-8192\",\n",
    "    response_format={\"type\": \"json_object\"},\n",
    ")\n",
    "\n",
    "summaries = json.loads(chat_completion.choices[0].message.content)[\"files\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'LICENSE', 'summary': 'MIT License agreement'},\n",
       " {'name': 'XXXXXX.ipynb', 'summary': 'Code snippet in a Jupyter Notebook'},\n",
       " {'name': 'XXXXXX.ipynb', 'summary': 'Code snippet using llama-index library'},\n",
       " {'name': 'XXXXXX.ipynb', 'summary': 'Code snippet with PROMPT variable'},\n",
       " {'name': 'XXXXXX.ipynb',\n",
       "  'summary': 'Empty notebook with `documents` variable'},\n",
       " {'name': 'requirements.txt', 'summary': 'List of requirements for a project'}]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "reader = SimpleDirectoryReader(input_dir=\".\")\n",
    "documents = reader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='d18f9c29-c487-4464-96f9-71a6b830efc2', embedding=None, metadata={'file_path': '/Users/iyaja/Git/llama-fs/LICENSE', 'file_name': 'LICENSE', 'file_size': 1074, 'creation_date': '2024-05-11', 'last_modified_date': '2024-05-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='MIT License\\n\\nCopyright (c) 2024 Ajay Arasanipalai\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1d5e9688-9bec-41e8-8d38-2e5240be4687', embedding=None, metadata={'file_path': '/Users/iyaja/Git/llama-fs/XXXXXX.ipynb', 'file_name': 'XXXXXX.ipynb', 'file_size': 117002, 'creation_date': '2024-05-11', 'last_modified_date': '2024-05-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='\\n\\n\\nimport openai\\nimport groq\\nimport os\\n\\n\\n# In[ ]:\\n\\n\\nos.environ[\"GROQ_API_\"] = \"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\"\\n\\n\\n# ', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='dfeda993-0d33-4c3d-b396-81675d7459bc', embedding=None, metadata={'file_path': '/Users/iyaja/Git/llama-fs/XXXXXX.ipynb', 'file_name': 'XXXXXX.ipynb', 'file_size': 117002, 'creation_date': '2024-05-11', 'last_modified_date': '2024-05-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='\\n\\n\\nfrom llama_index.core import SimpleDirectoryReader\\n\\nreader = SimpleDirectoryReader(input_dir=\"sample_data\")\\ndocuments = reader.load_data()\\n\\n\\n# ', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='98775353-6106-455d-830e-e5e6faf76393', embedding=None, metadata={'file_path': '/Users/iyaja/Git/llama-fs/XXXXXX.ipynb', 'file_name': 'XXXXXX.ipynb', 'file_size': 117002, 'creation_date': '2024-05-11', 'last_modified_date': '2024-05-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='\\n\\n\\nPROMPT = \"\"\"\\nThe following is a list of files, their metadata, and contents. Read them and create a \\n\"\"\".strip()\\n\\n\\n# In[ ]:\\n\\n\\n{\\n    \"name\" : \\n    \"content_summary\": \\n    \"last_edited\": \\n}\\n\\njson.hu\\n\\n\\n# ', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ed0c45f2-ecca-46a2-9fc2-b203d55c0564', embedding=None, metadata={'file_path': '/Users/iyaja/Git/llama-fs/XXXXXX.ipynb', 'file_name': 'XXXXXX.ipynb', 'file_size': 117002, 'creation_date': '2024-05-11', 'last_modified_date': '2024-05-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='\\n\\n\\ndocuments\\n\\n\\n# In[ ]:\\n\\n\\n\\n\\n', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9a78b139-0676-4bf4-a943-adad53a625cd', embedding=None, metadata={'file_path': '/Users/iyaja/Git/llama-fs/requirements.txt', 'file_name': 'requirements.txt', 'file_type': 'text/plain', 'file_size': 49, 'creation_date': '2024-05-11', 'last_modified_date': '2024-05-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='ollama\\nchromadb\\nllama-index\\nlitellm\\ngroq\\ndocx2txt', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\n",
    "The following is a list of files, their metadata, and contents. Read them and create a \n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('.', ['sample_data', '.git', '.vscode', 'notebooks'], ['LICENSE', 'requirements.txt', 'XXXXXX.ipynb', '.gitignore'])\n",
      "('./sample_data', [], ['2402.05602v1.pdf', 'd20e3b9a-9981-41c4-a6f7-dc1bafff4761.JPG'])\n",
      "('./.git', ['objects', 'info', 'logs', 'hooks', 'refs'], ['ORIG_HEAD', 'config', 'HEAD', 'description', 'index', 'packed-refs', 'FETCH_HEAD'])\n",
      "('./.git/objects', ['da', 'fb', 'pack', '1f', 'info', 'ba', '15', '76', '2e', '8b', '14'], [])\n",
      "('./.git/objects/da', [], ['468ee3c644e857a2e106ca4a11783998f298c6'])\n",
      "('./.git/objects/fb', [], ['1650ab30d9340080ca61c957b1a642cf4ac39a'])\n",
      "('./.git/objects/pack', [], ['pack-c6c1b461e7153ae493a82d75be7b87bbcf1c9e7e.idx', 'pack-c6c1b461e7153ae493a82d75be7b87bbcf1c9e7e.pack'])\n",
      "('./.git/objects/1f', [], ['96174d96c5f15ae9ac8a93d2d74dc52bd026c7'])\n",
      "('./.git/objects/info', [], [])\n",
      "('./.git/objects/ba', [], ['4da97535284af9f8825bb03df7539e817a5b2d'])\n",
      "('./.git/objects/15', [], ['2e80ab5c4ce5ebcfc8a3b2c8450f6f5f995c88'])\n",
      "('./.git/objects/76', [], ['37a14821de6ad1e347f9b0b2c79aa5857d7eb9'])\n",
      "('./.git/objects/2e', [], ['0e6e4d08f38b02ff8f0b58a5591234b3d7c511'])\n",
      "('./.git/objects/8b', [], ['464ca65dedd1c3446a9211c195cadf862af336'])\n",
      "('./.git/objects/14', [], ['5a1ef29d34467b847230604fdbdd4a5673929d'])\n",
      "('./.git/info', [], ['exclude'])\n",
      "('./.git/logs', ['refs'], ['HEAD'])\n",
      "('./.git/logs/refs', ['heads', 'remotes'], [])\n",
      "('./.git/logs/refs/heads', [], ['main'])\n",
      "('./.git/logs/refs/remotes', ['origin'], [])\n",
      "('./.git/logs/refs/remotes/origin', [], ['HEAD', 'main'])\n",
      "('./.git/hooks', [], ['commit-msg.sample', 'pre-rebase.sample', 'pre-commit.sample', 'applypatch-msg.sample', 'fsmonitor-watchman.sample', 'pre-receive.sample', 'prepare-commit-msg.sample', 'post-update.sample', 'pre-merge-commit.sample', 'pre-applypatch.sample', 'pre-push.sample', 'update.sample', 'push-to-checkout.sample'])\n",
      "('./.git/refs', ['heads', 'tags', 'remotes'], [])\n",
      "('./.git/refs/heads', [], ['main'])\n",
      "('./.git/refs/tags', [], [])\n",
      "('./.git/refs/remotes', ['origin'], [])\n",
      "('./.git/refs/remotes/origin', [], ['HEAD', 'main'])\n",
      "('./.vscode', [], ['settings.json'])\n",
      "('./notebooks', [], ['data_loading_processing.ipynb'])\n"
     ]
    }
   ],
   "source": [
    "for _ in os.walk(\".\"):\n",
    "    print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"name\" : \n",
    "    \"content_summary\": \n",
    "    \"last_edited\": \n",
    "}\n",
    "\n",
    "json.hu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='5f3833c1-ef33-4410-a729-61c6bf964a44', embedding=None, metadata={'page_label': '1', 'file_name': '2402.05602v1.pdf', 'file_path': '/Users/iyaja/Git/llama-fs/sample_data/2402.05602v1.pdf', 'file_type': 'application/pdf', 'file_size': 14982917, 'creation_date': '2024-05-11', 'last_modified_date': '2024-05-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='AttnLRP: Attention-Aware Layer-wise Relevance Propagation\\nfor Transformers\\nReduan Achtibat1Sayed Mohammad Vakilzadeh Hatefi1Maximilian Dreyer1\\nAakriti Jain1Thomas Wiegand1,2,3Sebastian Lapuschkin1,†Wojciech Samek1,2,3,†\\n1Fraunhofer Heinrich-Hertz-Institute, 10587 Berlin, Germany\\n2Technische Universit ¨at Berlin, 10587 Berlin, Germany\\n3BIFOLD – Berlin Institute for the Foundations of Learning and Data, 10587 Berlin, Germany\\n†corresponding authors: {wojciech.samek,sebastian.lapuschkin }@hhi.fraunhofer.de\\nAbstract\\nLarge Language Models are prone to biased\\npredictions and hallucinations, underlining the\\nparamount importance of understanding their\\nmodel-internal reasoning process. However,\\nachieving faithful attributions for the entirety\\nof a black-box transformer model and main-\\ntaining computational efficiency is an unsolved\\nchallenge. By extending the Layer-wise Rel-\\nevance Propagation attribution method to han-\\ndle attention layers, we address these challenges\\neffectively. While partial solutions exist, our\\nmethod is the first to faithfully and holistically\\nattribute not only input but also latent represen-\\ntations of transformer models with the computa-\\ntional efficiency similar to a singular backward\\npass. Through extensive evaluations against ex-\\nisting methods on Llama 2, Flan-T5 and the Vi-\\nsion Transformer architecture, we demonstrate\\nthat our proposed approach surpasses alterna-\\ntive methods in terms of faithfulness and enables\\nthe understanding of latent representations, open-\\ning up the door for concept-based explanations.\\nWe provide an open-source implementation on\\nGitHub1.\\n1. Introduction\\nThe attention mechanism (Vaswani et al., 2017) became\\nan essential component of large transformers due to its\\nunique ability to handle multimodality and to scale to bil-\\nlions of training samples. While these models demonstrate\\nimpressive performance in text and image generation, they\\nare prone to biased predictions and hallucinations (Huang\\net al., 2023), which hamper their widespread adoption.\\nTo overcome these limitations, it is crucial to understand\\n1https://github.com/rachtibat/LRP-for-Transformers\\nexplanation for “ dog”inputfaithfulness\\nlatent \\nattributionscomputational \\nefficiencyA ttnLRP (ours)SmoothGr adGr ad×A ttnRollA tMan\\nFigure 1. By optimizing LRP for transformer-based architectures,\\nour LRP variant outperforms other state-of-the-art methods in\\nterms of explanation faithfulness and computational efficiency.\\nWe further are able to explain latent neurons inside and outside\\nthe attention module, allowing us to interact with the model. A\\nmore detailed discussion on the differences between AttnLRP and\\nother LRP variants can be found in Appendix A.2.2. Heatmaps\\nfor other methods are illustrated in Appendix Figure 6. Legend:\\nhighly ( +), semi- ( ◦), not suited ( −). Credit: Nataba/iStock.\\nthe latent reasoning process of transformer models. Re-\\nsearchers started using the attention mechanism of trans-\\nformers as a means to understand how input tokens inter-\\nact with each other. Attention maps contain rich informa-\\ntion about the data distribution (Clark et al., 2019; Caron\\net al., 2021), even allowing for image data segmentation.\\nHowever, attention, by itself, is inadequate for compre-\\nhending the full spectrum of model behavior (Wiegreffe\\nand Pinter, 2019). Similar to latent activations, attention\\nis not class-specific and solely provides an explanation for\\nthe softmax output (in attention layers) while disregarding\\nother model components. Recent works (Geva et al., 2021;\\nDai et al., 2022), e.g., have discovered that factual knowl-\\nedge in Large Language Models (LLMs) is stored in Feed-\\nForward Network (FFN) neurons, separate from attention\\nlayers. Further, attention-based attribution methods such\\nas rollout (Abnar and Zuidema, 2020; Chefer et al., 2021a)\\n1arXiv:2402.05602v1  [cs.CL]  8 Feb 2024', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='34d478fb-205d-4ea3-b016-012246b857f5', embedding=None, metadata={'page_label': '2', 'file_name': '2402.05602v1.pdf', 'file_path': '/Users/iyaja/Git/llama-fs/sample_data/2402.05602v1.pdf', 'file_type': 'application/pdf', 'file_size': 14982917, 'creation_date': '2024-05-11', 'last_modified_date': '2024-05-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='activ ate \\u2028\\n neur on\\nactiv ate \\u2028\\n neur onIce bears liv e in the ...\\nAr cticDeser tCandy St or e\\ndisable\\u2028\\n neur on“ dr y spells, little water , T amil, arid \\nclimates, dr y er periods, dr y out”“ candy , sugar , sweets, conf ection ”\\n“ coldest, fr eezing, winter , Januar y ,\\nF ebruar y , temper atur e ”most activ ating pr ompts (A ttnLRP-guided)INPUT\\nOUTPUTOUTPUTOUTPUT\\nFFN blockother manipulations\\nFigure 2. AttnLRP combined with ActMax allows to identify rel-\\nevant neurons and gain insights into their encodings. This allows\\none to manipulate the latent representations and, e.g., to change\\nthe output “Arctic” (by disabling the corresponding neuron) to\\n“Desert” or “Candy Store” (by activating the respective neurons).\\nSee also Section 4.3.\\nresult in checkerboard artifacts, as visible in Figure 1 for\\na Vision Transformer (ViT). Researchers thus have turned\\nto model-agnostic approaches that aim to provide a holistic\\nexplanation of the model’s behavior (Miglani et al., 2023),\\nincluding, e.g., perturbation and gradient-based methods.\\nMethods based on feature perturbation require excessive\\namounts of compute time (and energy), making their appli-\\ncation uneconomically, especially for large architectures.\\nGradient-based methods, on the other hand, are highly effi-\\ncient but suffer from noisy gradients and low faithfulness,\\nas evaluated in Section 4.1. Consequently, for understand-\\ning latent neurons, perturbation methods remain often the\\npreferred choice (Meng et al., 2022; Bills et al., 2023).\\nAnother option is to take advantage of the versatility of\\nrule-based backpropagation methods, such as Layer-wise\\nRelevance Propagation (LRP). These methods allow for the\\ncustomization of propagation rules to accommodate novel\\noperations, allowing for more faithful explanations and re-\\nquiring only a singular backward pass. Attempts to ap-\\nply LRP to non-linear attention, however, have faced chal-\\nlenges such as numerical instability, lack of faithfulness, or\\ncompletely circumventing the non-linear softmax problem,\\nsee Appendix A.2.2.\\nContributions In this work, we introduce AttnLRP, an\\nextension of LRP within the Deep Taylor Decomposition\\nframework (Montavon et al., 2017), with the particular re-\\nquirements necessary for attributing non-linear attention\\naccurately. AttnLRP allows explaining transformer-based\\nmodels with high faithfulness and efficiency, while also al-\\nlowing attribution of latent neurons and providing insights\\ninto their role in the generation process (see Figure 2).\\n1. We derive novel efficient and faithful LRP attribution\\nrules for non-linear attention within the Deep TaylorDecomposition framework, demonstrating their supe-\\nriority over the state-of-the-art and successfully tack-\\nling the noise problem in ViTs.\\n2. We illustrate how to gain insights into a LLM gener-\\nation process by identifying relevant neurons and ex-\\nplaining their encodings.\\n3. We provide an efficient and ready-to-use open source\\nimplementation of AttnLRP for transformers.\\n2. Related Work\\nWe present an overview of related work for various model-\\nagnostic and transformer-specialized attribution methods.\\n2.1. Perturbation & Local Surrogates\\nIn perturbation analysis, such as occlusion-based attribu-\\ntion (Zeiler and Fergus, 2014) or SHAP (Lundberg and\\nLee, 2017), the input features are repeatedly perturbed\\nwhile the effect on the model output is measured (Fong\\nand Vedaldi, 2017). AtMan (Deb et al., 2023) is specifi-\\ncally adapted to the transformer architecture, where tokens\\nare not suppressed in the input space, but rather in the la-\\ntent attention weights. Interpretable local surrogates, on\\nthe other hand, replace complex black-box models with\\nsimpler linear models that locally approximate the model\\nfunction being explained. Since the surrogate has low com-\\nplexity, interpretability is facilitated. Prominent methods\\ninclude LIME (Ribeiro et al., 2016) and LORE (Guidotti\\net al., 2018).\\nWhile these approaches are model-agnostic and memory\\nefficient, they have a high computational cost in terms of\\nforward passes. Furthermore, explanations generated on\\nsurrogate models cannot explain the hidden representations\\nof the original model. Finally, latent attributions wrt. the\\nprediction must be computed for each layer separately, in-\\ncreasing the computational cost further.\\n2.2. Attention-based\\nThese methods take advantage of the attention mechanism\\nin transformer models. Although attention maps capture\\nparts of the data distribution, they lack class specificity\\nand do not provide a meaningful interpretation of the final\\nprediction (Wiegreffe and Pinter, 2019). Attention Roll-\\nout (Abnar and Zuidema, 2020) attempts to address the is-\\nsue by sequentially connecting attention maps of all lay-\\ners. However, the resulting attributions are still not specific\\nto individual outputs and exhibit substantial noise. Hence,\\n(Gildenblat, 2023) has found that reducing noise in atten-\\ntion rollout can be achieved by filtering out excessively\\nstrong outlier activations. To enable class-specificity, the\\nwork of (Chefer et al., 2021b) proposed a novel rollout pro-\\n2', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='b43873e5-63ff-47e0-872a-ca8b9145f041', embedding=None, metadata={'page_label': '3', 'file_name': '2402.05602v1.pdf', 'file_path': '/Users/iyaja/Git/llama-fs/sample_data/2402.05602v1.pdf', 'file_type': 'application/pdf', 'file_size': 14982917, 'creation_date': '2024-05-11', 'last_modified_date': '2024-05-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='cedure wherein the attention’s activation is mean-weighted\\nusing a combination of the gradient and LRP-inspired rel-\\nevances. It is important to note that this approach yields\\nan approximation of the mean squared relevance value,\\nwhich diverges from the originally defined notion of ”rel-\\nevance“ or ”importance“ of additive explanatory models\\nsuch as SHAP (Lundberg and Lee, 2017) or LRP (Bach\\net al., 2015). Subsequent empirical observations by (Chefer\\net al., 2021a) revealed that an omission of LRP-inspired rel-\\nevances and a sole reliance on a positive mean-weighting\\nof the attention’s activation with the gradient improved the\\nfaithfulness inside cross-attention layers. Though, this ap-\\nproach can only attribute positively and does not consider\\ncounteracting evidence.\\nAttention-rollout based approaches, while offering advan-\\ntages in terms of computational efficiency and conceptual\\nsimplicity, have significant drawbacks. Primarily, they suf-\\nfer from a limited resolution in the input attribution maps,\\nresulting in undesirable checkerboard artifacts cf. Figure 1.\\nMoreover, they are unable to attribute hidden latent fea-\\ntures beyond the softmax output. Consequently, these ap-\\nproaches only provide explanations for a fraction of the\\nmodel, thereby compromising the overall fidelity and limit-\\ning the feasibility of explanations within the hidden space.\\n2.3. Backpropagation-based\\nInput×Gradient (Simonyan et al., 2014) linearizes the\\nmodel by utilizing the gradient. However, this approach\\nis vulnerable to gradient shattering (Balduzzi et al., 2017;\\nDombrowski et al., 2022), leading to noisy attributions in\\ndeep models. Consequently, several works aim to denoise\\nthese attributions. SmoothGrad (Smilkov et al., 2017) and\\nIntegrated Gradients (Sundararajan et al., 2017) have at-\\ntempted to address this issue but have been unsuccessful in\\nthe case of large transformers, as demonstrated in the ex-\\nperiments in Section 4.1. (Chefer et al., 2021b) adapted\\nGrad-CAM (Selvaraju et al., 2017) to transformer models\\nby weighting the last attention map with the gradient.\\nModified backpropagation methods, such as LRP (Bach\\net al., 2015), decompose individual layers instead of lin-\\nearizing the entire model. They modify the gradient to pro-\\nduce more reliable attributions (Arras et al., 2022). The\\nwork (Ding et al., 2017) was the first to apply standard LRP\\non non-linear attention layers, while (V oita et al., 2021)\\nproposed an improved variant building upon Deep Taylor\\ndecomposition. Nonetheless, both variants can lead to nu-\\nmerical instabilities in the softmax and do not fulfill the\\nconservation property (3) in matrix multiplication (Lemma\\n3 of (Chefer et al., 2021b)). (Ali et al., 2022) considerably\\nimproved attributions by regarding the non-linear softmax\\noperation as constant attributing relevance solely through\\nthe value path and disregarding the softmax operation en-tirely. In Appendix A.2.2, we compare the different LRP-\\nvariants.\\n3. Attention-Aware LRP for Transformers\\nFirst, we motivate LRP in the framework of additive ex-\\nplanatory models. Then, we generalize the design of new\\nrules for non-linear operations. Finally, we apply our\\nmethodology successively on each operation utilized in a\\ntransformer model to derive efficient and faithful rules.\\n3.1. Layer-wise Relevance Propagation\\nLayer-wise Relevance Propagation (LRP) (Bach et al.,\\n2015; Montavon et al., 2019) belongs to the family of ad-\\nditive explanatory models, which includes the well-known\\nShapley (Lundberg and Lee, 2017), Gradient ×Input (Si-\\nmonyan et al., 2014) and DeepLIFT (Shrikumar et al.,\\n2017) methods.\\nThe underlying assumption of such models is that a func-\\ntionfjwith Ninput features x={xi}N\\ni=1can be de-\\ncomposed into individual contributions of single input vari-\\nables Ri←j(called “relevances”). Here, Ri←jdenotes the\\namount of output jthat is attributable to input i, which,\\nwhen added together, equals (or is proportional to) the orig-\\ninal function value. Mathematically, this can be written as:\\nfj(x)∝Rj=NX\\niRi←j (1)\\nIf an input iis connected to several outputs j,e.g., a mul-\\ntidimensional function f, the contributions of each output j\\nare losslessly aggregating together.\\nRi=X\\njRi←j. (2)\\nThis provides us with ”importance values” for the input\\nvariables, which reveal their direct contribution to the final\\nprediction.\\nUnlike other methods, LRP treats a neural network as a lay-\\nered directed acyclic graph, where each neuron jin layer l\\nis modeled as a function node fl\\njthat is individually decom-\\nposed according to equation (1). Beginning at the model\\noutput L, the initial relevance value RL\\nj∝fL\\njis succes-\\nsively distributed to its prior network neurons one layer at a\\ntime. Hence, LRP follows the flow of activations computed\\nduring the forward pass through the model in the opposite\\ndirection, from output fLback to input layer f1.\\nThis decomposition characteristic of LRP gives rise to the\\nimportant conservation property :\\nRl−1=X\\niRl−1\\ni=X\\niX\\njRl−1\\ni←j=X\\njRl\\nj=Rl,(3)\\n3', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='2e797521-6b8d-4383-980c-f65b65100fb5', embedding=None, metadata={'page_label': '4', 'file_name': '2402.05602v1.pdf', 'file_path': '/Users/iyaja/Git/llama-fs/sample_data/2402.05602v1.pdf', 'file_type': 'application/pdf', 'file_size': 14982917, 'creation_date': '2024-05-11', 'last_modified_date': '2024-05-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='ensuring that the sum of all relevance values in each layer\\nremains constant. This property allows for meaningful at-\\ntribution, as the scale of each relevance value can be related\\nto the original function output fL.\\n3.1.1. D ECOMPOSITION THROUGH LINEARIZATION\\nTo design a faithful attribution method, the challenge lies in\\nidentifying a meaningful distribution rule Ri←j. Possible\\nsolutions encompass all decompositions that adhere to the\\nconservation property (3). However, for a decomposition\\nto be considered faithful , it should approximate the charac-\\nteristics of the original function as closely as possible.\\nIn this paper, we take advantage of the Deep Taylor De-\\ncomposition framework (Montavon et al., 2017) to locally\\nlinearize and decompose neural network operations into in-\\ndependent contributions. As a special case, we further es-\\ntablish the relationship between one derived rule and the\\nShapley Values framework in Section 3.3.2.\\nWe start by computing a first-order Taylor expansion at a\\nreference point ˜x. For the purpose of simplifying the equa-\\ntion, we assume that the reference point ˜xis constant:\\nfj(x) =fj(˜x) +X\\niJji(˜x) (xi−˜xi) +O(|x−˜x|2)(4)\\n=X\\niJjixi+fj(˜x)−X\\niJji˜xi+O(|x−˜x|2)\\n| {z }\\nbias˜bj\\nwhere Ois the approximation error in Big- Onotation and\\nthe Jacobian Jis evaluated at reference point ˜x, that is in the\\nfollowing omitted for brevity2. The bias term represents the\\nconstant portion of the function and the approximation er-\\nror that cannot be directly attributed to the input variables.\\nWe substitute the neural network function with its first-\\norder expansion and assert its proportionality to a rele-\\nvance value Rjthrough multiplication with a constant fac-\\ntorc∈Rwithfj(x)̸= 0.\\nRj=fj(x)c= X\\niJjixi+˜bj!\\nRj\\nfj(x)\\nGenerally, we focus on attributing the input variables and\\nhence ignore the contribution of the bias term (Bach et al.,\\n2015). However, it is important to note that the bias ab-\\nsorbs part of the relevance and that the conservation prop-\\nerty (3) still holds if the bias is regarded as an additional\\nneuron without connection to the input. Alternatively, the\\nbias term can be distributed equally among the input vari-\\nables, as explained in Appendix A.2.1.\\nComparing with Equation (1), we identify Ri←jas the\\nsummands and apply Equation (2) to the input variables. In\\n2if˜x=x, this is equivalent to Gradient ×Inputaddition, we insert stabilizing factor ε(usually set to 10−6)\\nwith the sign of fj(x)to allow for the case fj(x) = 0 :\\nRi=X\\njRi←j=X\\njJjixiRj\\nfj(x) +εsign(fj(x))(5)\\nIn the following, sign (fj(x))is omitted for brevity.\\nTo benefit from GPU parallelization, this formula can be\\nwritten in matrix form:\\n⇒Rl−1=x⊙JT·Rl⊘(f(x) +ε)\\nwhere ⊙denotes the Hadamard product and ⊘element-\\nwise division. This formula can be efficiently imple-\\nmented in automatic differentiation libraries, such as Py-\\nTorch (Paszke et al., 2019). Compared to a basic backward\\npass, we have additional computational complexity for the\\nelement-wise operations.\\n3.2. Attributing the Multilayer Perceptron\\nCommonly a Multilayer Perceptron consists of a linear\\nlayer with a (component-wise) non-linearity producing in-\\nput activations for the succeeding layer(s):\\nzj=X\\niWjixi+bj (6)\\naj=σ(zj) (7)\\nwhere Wjiare the weight parameters and σconstitutes a\\n(component-wise) non-linearity.\\n3.2.1. T HEε-ANDγ-LRP RULE\\nLinearizing linear layers (6) at any point x∈RNresults in\\nthe fundamental ε-LRP (Bach et al., 2015) rule\\nRi=X\\njWjixiRj\\nzj(x) +ε(8)\\nThe bias bj(Equation (6)) absorbs a portion of the rele-\\nvance. The proof is omitted for brevity. We employ the\\nε-LRP rule on all linear layers, unless specified otherwise.\\nIn models with many layers, the gradient of a linear layer\\n(equal to the weight matrix W) can cause noisy attributions\\ndue to the gradient shattering effect (Balduzzi et al., 2017;\\nDombrowski et al., 2022). To mitigate this noise, it is best\\npractice to use the γ-LRP rule (Montavon et al., 2019), an\\nextension to improve the signal-to-noise ratio. We have ob-\\nserved that this effect is significantly pronounced in ViTs\\nwhile LLMs lack visible noise. Therefore, we only apply\\ntheγ-LRP rule to linear layers in ViTs. For more details,\\nplease refer to Appendix A.2.3.\\n4', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='38d36858-a77d-48bb-862b-d1c7431b0f4a', embedding=None, metadata={'page_label': '5', 'file_name': '2402.05602v1.pdf', 'file_path': '/Users/iyaja/Git/llama-fs/sample_data/2402.05602v1.pdf', 'file_type': 'application/pdf', 'file_size': 14982917, 'creation_date': '2024-05-11', 'last_modified_date': '2024-05-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='3.2.2. H ANDLING ELEMENT -WISE NON-LINEARITIES\\nSince element-wise non-linearities have only a single input\\nand output variable, the decomposition of equation (1) is\\nthe operation itself. Therefore, the entire incoming rele-\\nvance Rl\\njcan only be assigned to the single input variable.\\nRl−1\\ni=Rl\\ni (9)\\nThe identity rule (9) is applied to all element-wise opera-\\ntions with a single input and single output variable.\\n3.3. Attributing Non-linear Attention\\nThe heart of the transformer architecture (Vaswani et al.,\\n2017) is non-linear attention\\nA=softmax\\x12Q·KT\\n√dk\\x13\\n(10)\\nO=A·V (11)\\nsoftmax j(x) =exj\\nP\\nkexk(12)\\nwhere ( ·) denotes matrix multiplication, K∈Rb×k×dkis\\nthe key matrix, Q∈Rb×q×dkis the queries matrix, and\\nV∈Rb×k×dvthe values matrix, and O∈Rb×k×dvis\\nthe final output of the attention mechanism. bis the batch\\ndimension including the number of heads, and dk, dvindi-\\ncate the embedding dimensions, and sq, skare the number\\nof query and key/value tokens.\\nFirst and foremost, the softmax function is highly non-\\nlinear. In addition, the matrix multiplication is bilinear,\\ni.e., linear in both of its input variables. In the following,\\nwe will derive relevance propagation rules for each of these\\noperations, taking into account considerations of efficiency.\\n3.3.1. H ANDLING THE SOFTMAX NON-LINEARITY\\nIn Section 3.1.1, we present a generalized approach to\\nlinearization that incorporates bias terms, allowing for\\nthe absorption of a portion of the relevance. However,\\n(Ali et al., 2022) advocates for a strict adherence to the\\nconservation property (3) and argues that a linear decom-\\nposition of a non-linear function should typically exclude\\na bias term. While we see the virtue of this approach for\\noperations such as RMSNorm (Zhang and Sennrich, 2019)\\nor matrix multiplication, where f(0) = 0 , we contend that\\na linearization of the softmax function should inherently\\nincorporate a bias term. This is due to the fact that even\\nwhen the input is zero, the softmax function yields a value\\nof1\\nN(where Nrepresents the dimension of the inputs)\\nwhich is analogous to a bias term.Proposition 3.1 Decomposing the softmax function\\nby a Taylor decomposition (4)at reference point xyields\\nthe following relevance propagation rule:\\nRl\\ni=xi(Rl+1\\ni−siX\\njRl+1\\nj) (13)\\nwhere sjdenotes the j-th output of the softmax function.\\nThe hidden bias term, which represents the approximation\\nerror, consequently absorbs a portion of the relevance.\\nThe proof can be found in Appendix A.3.1.\\nNote, that the works (V oita et al., 2021; Chefer et al.,\\n2021b; Ali et al., 2022) propose to handle the bias term\\ndifferently to strictly enforce the conservation property (3).\\n(V oita et al., 2021) linearizes at xbut distributes the\\nbias term equally on all input variables, while (Chefer\\net al., 2021b) applies the element-wise identity rule (9) and\\nhence omits the bias term completely. Both variants can\\nlead to severe numerical instabilities as discussed in Ap-\\npendix A.2.1 and seen empirically in our preliminary ex-\\nperiments. Finally, (Ali et al., 2022) regards the attention\\nmatrix Ain equation (11) as constant, attributing relevance\\nsolely through the value path and disregarding the softmax\\noperation entirely. A more detailed discussion on the differ-\\nences of the LRP variants can be found in Appendix A.2.2.\\n3.3.2. H ANDLING MATRIX -MULTIPLICATION\\nSince f(0,0) = 0 holds, it is desirable to decompose the\\nmatrix multiplication without a bias term. To achieve this,\\nwe break down the matrix multiplication into an affine op-\\neration involving summation and a bi-linear part involving\\nelement-wise multiplication.\\nOjp=X\\niAjiVip|{z}\\nbi-linear part\\nThe summation already provides a decomposition in the\\nform of equation (1), and we only need to decompose the\\nindividual summands AjiVip. Since multiplication is a\\ncommutative operation, assigning equal relevance values\\nto both operands is reasonable.\\nProposition 3.2 Decomposing element-wise multiplication\\nwithNinput variables of the form\\nfj(x) =NY\\nixi\\nby Shapley (with baseline zero) or Taylor decomposition (4)\\nat reference point x(without bias or distributing the bias\\nuniformely) yields the following uniform relevance propa-\\ngation rule:\\nRi←j(xi) =1\\nNRj. (14)\\n5', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='663bfb79-bf59-45d8-aee3-0b49acd26b9a', embedding=None, metadata={'page_label': '6', 'file_name': '2402.05602v1.pdf', 'file_path': '/Users/iyaja/Git/llama-fs/sample_data/2402.05602v1.pdf', 'file_type': 'application/pdf', 'file_size': 14982917, 'creation_date': '2024-05-11', 'last_modified_date': '2024-05-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='The proof can be found in Appendix A.3.2. Consequently,\\nthe combined rule can be effectively computed using:\\nProposition 3.3 Decomposing matrix multiplication with\\na sequential application of the uniform rule (14) and the\\nε-rule (8) yields the following relevance propagation rule:\\nRl−1\\nji(Aji) =X\\npAjiVipRl\\njp\\n2Ojp+ε(15)\\nThere is no bias term absorbing relevance. For Vip, we\\nsum over the jindices. The proof can be found in Ap-\\npendix A.3.3. By employing this rule, we are able to main-\\ntain strict adherence to the conservation property (3), while\\nalso preserving numerical stability.\\n3.3.3. H ANDLING NORMALIZATION LAYERS\\nCommonly used normalization layers in Transformers in-\\nclude LayerNorm (Ba et al., 2016) and RMSNorm (Zhang\\nand Sennrich, 2019). These layers apply affine transforma-\\ntions and non-linear normalization sequentially.\\nLayerNorm (x) =xj−E[x]p\\nVar[x] +εγj+βj (16)\\nRMSNorm (x) =xjq\\n1\\nNP\\nkx2\\nk+εγj (17)\\nwhere ε, γj, βj∈R.Affine transformations such as the\\nmultiplicative weighting of the output or the subtraction of\\nthe mean value are linear operations that can be attributed\\nby the ε-LRP rule. Normalization, on the other hand, is\\nnon-linear and requires separate considerations. As such,\\nwe focus on the following function:\\nfj(x) =xj\\ng(x)(18)\\nwhere g(x) =p\\nVar[x] +εorg(x) =q\\n1\\nNP\\nkx2\\nk+ε.\\nThe work (Ali et al., 2022) demonstrates that when lin-\\nearizing LayerNorm at x, the bias term absorbs most of\\nthe relevance equal to Var [x]/(Var[x] +ε), effectively ab-\\nsorbing 99% of the relevance with commonly used values\\nofε= 10−6and Var [x] = 1 . Hence, a linearization at xis\\nnot meaningful. As a solution, (Ali et al., 2022) proposes to\\nskip this operation with the identity rule. In the following,\\nwe prove that this heuristic can be derived from the Deep\\nTaylor Decomposition framework.\\nProposition 3.4 Decomposing LayerNorm or RMSNorm by\\na Taylor decomposition (4)with reference point 0(without\\nbias or distributing the bias uniformly) yields the identity\\nrelevance propagation rule:\\nRl−1\\ni=Rl\\ni (19)\\nactiv ated \\nneur on+...inputsr ele v anceactiv ationa)\\nb)...pr oject on v ocabular y\\n[..] and the coldest is Januar y , about -6 °C.\\n[..] temper atur e of 37 °C t o the near-fr eezing [..][..] winter temper atur es can be as low as [..] 1.07fr eezing0.76Ar ctic...0.55skiing0.39Rudolph\\nt op \\npr omoted\\nmost \\nactiv atingFFN blockFigure 3. There are two approaches for understanding knowledge\\nneurons: (a) Neuron 3948 at the last non-linearity in FFN 17\\nof the Phi-1.5 model selects a weight row to add to the residual\\nstream. This weight row projected on the vocabulary spans top-\\nics about ice, cold places and winter sport. (b) Sentences that\\nmaximally activate this neuron contain references about coldness.\\nAttributing the neuron with AttnLRP highlights the most rele-\\nvant tokens inside the input sentences. Note, although not illus-\\ntrated here, AttnLRP can also attribute linear layers inside atten-\\ntion modules. Inspired by (V oita et al., 2023).\\nThere is no bias that absorbs relevance. The proof is given\\nin Appendix A.3.4\\nThis rule enforces a strict notion of conservation, while be-\\ning highly efficient by excluding normalization operations\\nfrom the computational graph. Experiments in Section 4.1\\nprovide evidence that this simplification is faithful.\\n3.4. Understanding Latent Features\\nAs we iterate through each layer and neuron during the at-\\ntribution process with AttnLRP, we obtain relevance values\\nfor each latent neuron as a by-product, which directly sig-\\nnify their importance for the prediction. Ranking this latent\\nrelevance enables us to identify the neurons and layers that\\nare most influential for the reasoning process of the model\\n(Achtibat et al., 2023). After identifying a group of neu-\\nrons, the subsequent step is to reveal the concept that is\\nrepresented by each neuron.\\nFor Convolutional Neural Networks (CNNs), single units\\n(i.e., neurons or filters) have been shown to correspond to\\ndistinct concepts, each fulfilling specific sub-tasks (Rad-\\nford et al., 2017). In order to find the most represen-\\ntative reference samples that explain the neuron’s encod-\\ning, researchers rely on Activation Maximization (Act-\\nMax) (Nguyen et al., 2016), where input samples are\\nsought that give rise to the highest activation value. We\\nfollow up on these observations and present the following\\nstrategy for understanding latent features:\\n6', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='76e8b431-01ce-44f1-91c3-72f99dd8f251', embedding=None, metadata={'page_label': '7', 'file_name': '2402.05602v1.pdf', 'file_path': '/Users/iyaja/Git/llama-fs/sample_data/2402.05602v1.pdf', 'file_type': 'application/pdf', 'file_size': 14982917, 'creation_date': '2024-05-11', 'last_modified_date': '2024-05-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='(1) Collect prompts that lead to the highest activation of a\\nunit. (2) Explain the unit’s activation using AttnLRP, al-\\nlowing to narrow down the relevant input tokens for the\\nchosen unit.\\nIn this work, we concentrate on knowledge neurons (Dai\\net al., 2022; V oita et al., 2023) that are situated at the last\\nnon-linearity in FFN layers zj=GELU (W1x). These\\nneurons possess intriguing properties, as shown in Fig-\\nure 3: They encode factual knowledge and upon activation,\\nthe corresponding row of the second weight matrix W2is\\nadded to the residual stream directly influencing the out-\\nput distribution of the model. By projecting this weight\\nrow onto the vocabulary, a distribution of the most proba-\\nble tokens across the vocabulary is obtained (Geva et al.,\\n2022). Applying AttnLRP on ActMax reference samples\\nand projecting the weight row on the vocabulary allow us\\nto understand in which context a neuron activates and how\\nits activation influences the prediction of the next token. In\\ncontrast to (Ali et al., 2022), AttnLRP also allows analyz-\\ning the key and value linear layers inside attention modules.\\n4. Experiments\\nOur experiments aim to answer the following questions:\\n(Q1) How faithful are our explanations compared to other\\nstate-of-the-art approaches?\\n(Q2) How efficient is LRP compared to perturbation-based\\nmethods?\\n(Q3) Can we understand latent representations and interact\\nwith LLMs?\\n4.1. Evaluating Explanations (Q1)\\nA reliable measure of faithfulness of an explanation are in-\\nput perturbation experiments (Samek et al., 2017). This\\napproach iteratively substitutes the most important tokens\\nin the input domain with a baseline value. If the attribution\\nmethod accurately identified the most important tokens, the\\nmodel’s confidence in the predicted output should rapidly\\ndecrease. The other way around, perturbing the least rel-\\nevant tokens first, should not affect the model’s prediction\\nand result in a slow decline of the model’s confidence. For\\nmore details, see Appendix B.2. Despite its drawbacks,\\nsuch as potentially introducing out-of-distribution manipu-\\nlations (Chang et al., 2018) and sensitivity towards the cho-\\nsen baseline value, this approach is widely adopted in the\\ncommunity. (Bl ¨ucher et al., 2024) has addressed this criti-\\ncism and introduced an enhanced metric by quantifying the\\narea between the least and most relevant order perturbation\\ncurves to obtain a robust measure. Hence, we will employ\\nthis improved metric to measure faithfulness. Appendix\\nFigure 4 illustrates a typical perturbation curve.In order to assess plausibility, we utilize the SQuAD v2\\nQuestion-Answering (QA) dataset (Rajpurkar et al., 2018),\\nwhich includes a ground truth mask indicating the correct\\nanswer within the question. We calculate attributions for\\naccurately answered questions and determine the Intersec-\\ntion over Union (IoU) between the positive attribution val-\\nues and the ground truth mask. This approach assumes that\\nthe model solely relies on the information provided in the\\nground truth mask, which is not entirely accurate but suffi-\\ncient for identifying a trend.\\n4.1.1. B ASELINES\\nWe evaluate the faithfulness on two self-attention models,\\na ViT-B-16 (Dosovitskiy et al., 2021) on ImageNet (Deng\\net al., 2009) classification and the Llama 2-7b (Touvron\\net al., 2023) model on IMDB movie review (Maas et al.,\\n2011) classification as well as next word prediction of\\nWikipedia (Wikimedia Foundation, 2023). To evaluate\\ncross-attention layers, we use the encoder-decoder model\\nFlan T5-XL (Chung et al., 2022) on the SQuAD v2 dataset.\\nWe denote our method as AttnLRP and compare it against\\na broad spectrum of methods including Input ×Gradient\\n(I×G), Integrated Gradients (IG), SmoothGrad (SmoothG),\\nAttention Rollout (AttnRoll), Gradient-weighted Attention\\nRollout (G ×AttnRoll) and Conservative Propagation (CP)-\\nLRP. As explained in Appendix A.2.3, we propose to ap-\\nply the γ-rule for AttnLRP in the case of ViTs. For bet-\\nter comparison, we also included an enhanced CP-LRP\\nbaseline, which also uses the γ-rule in the ViTs experi-\\nment. The LRP variants introduced by (V oita et al., 2021;\\nChefer et al., 2021b) are excluded due to numerical insta-\\nbilities observed in preliminary experiments, see also Ap-\\npendix A.2.1. Further, we utilize the Grad-CAM adaptation\\ndescribed in (Chefer et al., 2021b). Specifically, we weight\\nthe last attention map with the gradient. Finally, we expand\\nupon AtMan by incorporating it into encoder-decoder mod-\\nels by suppressing tokens in all self-attention layers within\\nthe encoder, while only doing so in cross-attention layers\\nwithin the decoder. For AtMan, SmoothGrad and Rollout-\\nmethods we perform a hyperparameter sweep over a subset\\nof the dataset. More details are in Appendix B.3.\\n4.1.2. D ISCUSSION\\nIn Table 1, it is visible that AttnLRP consistently outper-\\nforms all the state-of-the-art methods in terms of faithful-\\nness, especially in Llama 2. We also observe that gradient-\\nbased approaches significantly suffer from noisy attribu-\\ntions, as reflected by the low faithfulness scores and illus-\\ntrated in example heatmaps in Appendix B.5. CP-LRP with\\nεapplied on all layers (as proposed in Ali et al. (2022)),\\nalso suffers from noisy gradients in ViTs. Applying the γ-\\nrule for CP-LRP and AttnLRP in ViTs improves the faith-\\nfulness substantially. Whereas AtMan does not perform\\n7', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='02e4dd99-e69f-49df-b7cf-09f87d4a47c2', embedding=None, metadata={'page_label': '8', 'file_name': '2402.05602v1.pdf', 'file_path': '/Users/iyaja/Git/llama-fs/sample_data/2402.05602v1.pdf', 'file_type': 'application/pdf', 'file_size': 14982917, 'creation_date': '2024-05-11', 'last_modified_date': '2024-05-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Table 1. Faithfulness scores as area between the least and most relevant order perturbation curves (Bl ¨ucher et al., 2024) on different\\nmodels and datasets. To assess plausibility, the IoU in the SQuAD v2 dataset is depicted. The higher a score, the better.\\nMethods ViT-B-16 Llama 2-7b Flan-T5-XL\\nImageNet IMDB Wikipedia SQuAD v2 SQuAD v2 IoU\\nRandom 0.01±0.01−0.01±0.05−0.07±0.13 0 .01±0.21 0 .079±0.001\\nInput×Grad (Simonyan et al., 2014) 0.80±0.03 0 .12±0.05 0 .18±0.13 0 .27±0.14 0 .386±0.003\\nIG (Sundararajan et al., 2017) 1.54±0.03 1 .23±0.05 4 .05±0.13 0 .77±0.14 0 .158±0.002\\nSmoothGrad (Smilkov et al., 2017) −0.04±0.03 0 .25±0.05−2.22±0.14 0 .16±0.15 0 .090±0.001\\nGradCAM (Chefer et al., 2021b) 0.27±0.04−0.82±0.05 2 .01±0.15 0 .94±0.14 0 .692±0.004\\nAttnRoll (Abnar and Zuidema, 2020) 1.31±0.03−0.64±0.05−3.49±0.15−0.42±0.14 0 .076±0.001\\nGrad×AttnRoll (Chefer et al., 2021a) 2.60±0.03 1 .61±0.05 9 .79±0.14−0.06±0.14 0 .531±0.002\\nAtMan (Deb et al., 2023) 0.70±0.02−0.20±0.05 3 .31±0.15 1 .01±0.15 0 .798±0.003\\nCP-LRP ( ε-rule, Ali et al. (2022)) 2.53±0.02 1 .72±0.04 7 .85±0.12 1 .74±0.14 0 .830±0.003\\nCP-LRP ( γ-rule for ViT, as proposed here) 6.06±0.02 - - - -\\nAttnLRP (ours) 6.19±0.022.50±0.0510.93±0.131.76±0.140.840±0.002\\nwell in unstructured tasks, i.e., next word prediction or\\nclassification, it achieves a high score in QA tasks. While\\nG×AttnRoll better reflects the model behavior in unstruc-\\ntured tasks compared to AtMan, it is affected by consider-\\nable background noise, resulting in a low IoU score in the\\nSQuAD v2 dataset.\\n4.2. Computational Complexity and Memory\\nConsumption (Q2)\\nTable 2 illustrates the computational complexity and mem-\\nory consumption of a single LRP-based attribution and\\nlinear-time perturbation, such as AtMan or a Shapley-based\\nmethod (Fatima et al., 2008). Linear-time perturbation\\nrequires NTforward passes, but has only a memory re-\\nquirement of O(1). Since LRP is a backpropagation-based\\nmethod, gradient checkpointing (Chen et al., 2016) tech-\\nniques can be applied. In checkpointing, LRP requires\\ntwo forward and one backward pass, while the memory re-\\nquirement scales logarithmic with the number of layers. In\\nAppendix B.6, we benchmark energy, time and memory\\nconsumption of LRP against perturbation-based methods\\nacross context- and model-sizes.\\nTable 2. Computational and memory complexity of LRP-based\\nand linear-time perturbation methods measured w.r.t. a single for-\\nward pass. NL: number of layers, NT: number of tokens\\nMethods Computational Memory\\nComplexity Consumption\\nLRP Checkpointing O(1) O(√NL)\\nPerturbation (linear) O(NT) O(1)4.3. Understanding & Manipulating Neurons (Q3)\\nIn our investigation, we use the Phi-1.5 model (Li et al.,\\n2023), which has a transformer-based architecture with\\na next-word prediction objective. We obtain reference\\nsamples for each knowledge neuron by collecting the\\nmost activating sentences over the Wikipedia summary\\ndataset (Scheepers, 2017).\\nTo illustrate, we consider the prompt: ‘ The ice bear\\nlives in the ’ which gives the corresponding predic-\\ntion: ‘ Arctic ’. Using AttnLRP, we determine the most\\nrelevant layers for predicting ‘ Arctic ’ as well as the spe-\\ncific neurons within the FFN layers contributing to this pre-\\ndiction. Our analysis reveals that the most relevant neurons\\nafter the first three layers are predominantly situated within\\nthe middle layers. Notably, one standout neuron #3948 in\\nlayer 17 activates on reference samples about cold tem-\\nperatures, as depicted in Figure 3. This observation is fur-\\nther validated by projecting the weight matrix of the second\\nFFN layer onto the vocabulary. The neuron shifts the out-\\nput distribution of the model to cold places, winter sports\\nand animals living in cold regions.\\nAnalogously, for the prompt ‘ Children love to\\neat sugar and ’ with the prediction ‘ sweets ’, the\\nmost relevant neuron’s ( layer 18 , neuron #5687 )\\nprojection onto the vocabulary signifies a shift in the\\nmodel’s focus towards the concept of candy, temptation\\nand sweetness in the vocabulary space. We interact with\\nthe model by deactivating neuron #3848 , and strongly\\namplifying the activation of neuron #5687 in the forward\\npass. This manipulation yields the following prediction\\nchange:\\n8', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='23b83905-5b4f-4728-8ca1-f6c56e8ee62c', embedding=None, metadata={'page_label': '9', 'file_name': '2402.05602v1.pdf', 'file_path': '/Users/iyaja/Git/llama-fs/sample_data/2402.05602v1.pdf', 'file_type': 'application/pdf', 'file_size': 14982917, 'creation_date': '2024-05-11', 'last_modified_date': '2024-05-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Prompt: Ice bears live in the\\nPrediction: sweet, sugary treats of the\\ncandy store.\\nWe further notice that neuron #4104 inlayer 17 en-\\ncodes for dryness, thirst and sand. Increasing its activation\\nchanges the output to ‘ desert ’ (illustrated in Figure 2).\\nWith AttnLRP, we are able to trace the most important\\nneurons in models with billions of parameters. This al-\\nlows us to systematically navigate the latent space to en-\\nable targeted modifications to reduce the impact of cer-\\ntain concepts (for example, ‘ coldness ’) and enhance the\\npresence of other concepts (for example, ‘ dryness ’), re-\\nsulting in discernible output changes. Such an approach\\nholds significant implications for transformer-based mod-\\nels, which have been difficult to manipulate and explain\\ndue to inherent opacity and size.\\n5. Conclusion\\nWe have extended the Layer-wise Relevance Propagation\\nframework to non-linear attention, proposing novel rules\\nfor the softmax and matrix-multiplication step and provid-\\ning interpretations in terms of Deep Taylor Decomposition.\\nOur AttnLRP method stands out due to its unique combina-\\ntion of simplicity, faithfulness, and efficiency. We demon-\\nstrate its applicability both for LLMs as well as ViTs, utiliz-\\ning the stabilizing effect of the γ-rule. In contrast to other\\nbackpropagation-based approaches, AttnLRP enables the\\naccurate attribution of neurons in latent space (also within\\nthe attention module), thereby introducing novel possibili-\\nties for real-time model interaction and interpretation.\\nLimitations & Open Problems\\nTo enhance efficiency and reduce memory consumption,\\ncustom GPU kernels analogously to FlashAttention (Dao\\net al., 2022) should be implemented for LRP rules. Tun-\\ning the γ-parameter in ViTs to obtain faithful attributions\\nis necessary.References\\nAbnar, S. and Zuidema, W. H. (2020). Quantifying atten-\\ntion flow in transformers. In Proceedings of the 58th An-\\nnual Meeting of the Association for Computational Lin-\\nguistics , pages 4190–4197.\\nAchtibat, R., Dreyer, M., Eisenbraun, I., Bosse, S., Wie-\\ngand, T., Samek, W., and Lapuschkin, S. (2023). From\\nattribution maps to human-understandable explanations\\nthrough concept relevance propagation. Nature Machine\\nIntelligence , 5(9):1006–1019.\\nAli, A., Schnake, T., Eberle, O., Montavon, G., M ¨uller, K.-\\nR., and Wolf, L. (2022). Xai for transformers: Better\\nexplanations through conservative propagation. In Inter-\\nnational Conference on Machine Learning , pages 435–\\n451. PMLR.\\nArras, L., Osman, A., and Samek, W. (2022). Clevr-\\nxai: A benchmark dataset for the ground truth evalua-\\ntion of neural network explanations. Information Fusion ,\\n81:14–40.\\nBa, J. L., Kiros, J. R., and Hinton, G. E. (2016). Layer\\nnormalization. arXiv preprint arXiv:1607.06450 .\\nBach, S., Binder, A., Montavon, G., Klauschen, F., M ¨uller,\\nK.-R., and Samek, W. (2015). On pixel-wise explana-\\ntions for non-linear classifier decisions by layer-wise rel-\\nevance propagation. PLoS ONE , 10(7):e0130140.\\nBalduzzi, D., Frean, M., Leary, L., Lewis, J., Ma, K. W.-\\nD., and McWilliams, B. (2017). The shattered gradients\\nproblem: If resnets are the answer, then what is the ques-\\ntion? In International Conference on Machine Learning ,\\npages 342–350. PMLR.\\nBills, S., Cammarata, N., Mossing, D., Till-\\nman, H., et al. (2023). Language models can\\nexplain neurons in language models. URL\\nhttps://openaipublic.blob.core.windows.net/neuron-\\nexplainer/paper/index.html (accessed: 14.05.2023) .\\nBl¨ucher, S., Vielhaben, J., and Strodthoff, N. (2024). De-\\ncoupling pixel flipping and occlusion strategy for consis-\\ntent xai benchmarks. arXiv preprint arXiv:2401.06654 .\\nCaron, M., Touvron, H., Misra, I., J ´egou, H., Mairal, J., Bo-\\njanowski, P., and Joulin, A. (2021). Emerging properties\\nin self-supervised vision transformers. In Proceedings\\nof the IEEE/CVF International Conference on Computer\\nVision , pages 9650–9660.\\nChang, C.-H., Creager, E., Goldenberg, A., and Duvenaud,\\nD. (2018). Explaining image classifiers by counterfac-\\ntual generation. arXiv preprint arXiv:1807.08024 .\\n9', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='3fcf47df-2386-4f57-ab58-1d4310f210fc', embedding=None, metadata={'page_label': '10', 'file_name': '2402.05602v1.pdf', 'file_path': '/Users/iyaja/Git/llama-fs/sample_data/2402.05602v1.pdf', 'file_type': 'application/pdf', 'file_size': 14982917, 'creation_date': '2024-05-11', 'last_modified_date': '2024-05-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Chefer, H., Gur, S., and Wolf, L. (2021a). Generic\\nattention-model explainability for interpreting bi-modal\\nand encoder-decoder transformers. In Proceedings of\\nthe IEEE/CVF International Conference on Computer\\nVision , pages 397–406.\\nChefer, H., Gur, S., and Wolf, L. (2021b). Transformer\\ninterpretability beyond attention visualization. In Pro-\\nceedings of the IEEE/CVF Conference on Computer Vi-\\nsion and Pattern Recognition , pages 782–791.\\nChen, T., Xu, B., Zhang, C., and Guestrin, C. (2016). Train-\\ning deep nets with sublinear memory cost. arXiv preprint\\narXiv:1604.06174 .\\nChung, H. W., Hou, L., Longpre, S., Zoph, B., Tay, Y .,\\nFedus, W., Li, Y ., Wang, X., Dehghani, M., Brahma,\\nS., et al. (2022). Scaling instruction-finetuned language\\nmodels. arXiv preprint arXiv:2210.11416 .\\nClark, K., Khandelwal, U., Levy, O., and Manning, C. D.\\n(2019). What does bert look at? an analysis of bert’s\\nattention. In Proceedings of the 2019 ACL Workshop\\nBlackboxNLP: Analyzing and Interpreting Neural Net-\\nworks for NLP , pages 276–286.\\nDai, D., Dong, L., Hao, Y ., Sui, Z., Chang, B., and Wei, F.\\n(2022). Knowledge neurons in pretrained transformers.\\nInProceedings of the 60th Annual Meeting of the Asso-\\nciation for Computational Linguistics (Volume 1: Long\\nPapers) , pages 8493–8502.\\nDao, T., Fu, D., Ermon, S., Rudra, A., and R ´e, C. (2022).\\nFlashattention: Fast and memory-efficient exact atten-\\ntion with io-awareness. Advances in Neural Information\\nProcessing Systems , 35:16344–16359.\\nDeb, M., Deiseroth, B., Weinbach, S., Schramowski, P.,\\nand Kersting, K. (2023). Atman: Understanding trans-\\nformer predictions through memory efficient attention\\nmanipulation. arXiv preprint arXiv:2301.08110 .\\nDeng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-\\nFei, L. (2009). Imagenet: A large-scale hierarchical im-\\nage database. In 2009 IEEE conference on computer vi-\\nsion and pattern recognition , pages 248–255. Ieee.\\nDing, Y ., Liu, Y ., Luan, H., and Sun, M. (2017). Visual-\\nizing and understanding neural machine translation. In\\nProceedings of the 55th Annual Meeting of the Associa-\\ntion for Computational Linguistics (Volume 1: Long Pa-\\npers) , pages 1150–1159.\\nDombrowski, A.-K., Anders, C. J., M ¨uller, K.-R., and\\nKessel, P. (2022). Towards robust explanations for deep\\nneural networks. Pattern Recognition , 121:108194.Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn,\\nD., et al. (2021). An image is worth 16x16 words: Trans-\\nformers for image recognition at scale. In 9th Interna-\\ntional Conference on Learning Representations, ICLR .\\nFatima, S. S., Wooldridge, M., and Jennings, N. R. (2008).\\nA linear approximation method for the shapley value.\\nArtificial Intelligence , 172(14):1673–1699.\\nFong, R. C. and Vedaldi, A. (2017). Interpretable ex-\\nplanations of black boxes by meaningful perturbation.\\nInIEEE International Conference on Computer Vision\\n(ICCV) , pages 3449–3457.\\nFryer, D., Str ¨umke, I., and Nguyen, H. (2021). Shapley\\nvalues for feature selection: The good, the bad, and the\\naxioms. IEEE Access , 9:144352–144360.\\nGeva, M., Caciularu, A., Wang, K., and Goldberg, Y .\\n(2022). Transformer feed-forward layers build predic-\\ntions by promoting concepts in the vocabulary space. In\\nProceedings of the 2022 Conference on Empirical Meth-\\nods in Natural Language Processing , pages 30–45.\\nGeva, M., Schuster, R., Berant, J., and Levy, O. (2021).\\nTransformer feed-forward layers are key-value memo-\\nries. In Proceedings of the 2021 Conference on Em-\\npirical Methods in Natural Language Processing , pages\\n5484–5495.\\nGildenblat, J. (2020. Accessed on Dec 01, 2023).\\nExploring explainability for vision transform-\\ners. https://jacobgil.github.io/deeplearning/vision-\\ntransformer-explainability.\\nGuidotti, R., Monreale, A., Ruggieri, S., Pedreschi, D.,\\nTurini, F., and Giannotti, F. (2018). Local rule-based ex-\\nplanations of black box decision systems. arXiv preprint\\narXiv:1805.10820 .\\nHuang, L., Yu, W., Ma, W., Zhong, W., Feng, Z., Wang, H.,\\nChen, Q., Peng, W., Feng, X., Qin, B., et al. (2023). A\\nsurvey on hallucination in large language models: Prin-\\nciples, taxonomy, challenges, and open questions. arXiv\\npreprint arXiv:2311.05232 .\\nLi, Y ., Bubeck, S., Eldan, R., Del Giorno, A., Gu-\\nnasekar, S., and Lee, Y . T. (2023). Textbooks are all\\nyou need ii: phi-1.5 technical report. arXiv preprint\\narXiv:2309.05463 .\\nLundberg, S. M. and Lee, S. (2017). A unified approach\\nto interpreting model predictions. In Advances in Neural\\nInformation Processing Systems 30 , pages 4765–4774.\\n10', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='845cfac0-b4be-4469-8684-7e669756c1ff', embedding=None, metadata={'page_label': '11', 'file_name': '2402.05602v1.pdf', 'file_path': '/Users/iyaja/Git/llama-fs/sample_data/2402.05602v1.pdf', 'file_type': 'application/pdf', 'file_size': 14982917, 'creation_date': '2024-05-11', 'last_modified_date': '2024-05-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Maas, A., Daly, R. E., Pham, P. T., Huang, D., Ng, A. Y .,\\nand Potts, C. (2011). Learning word vectors for senti-\\nment analysis. In Proceedings of the 49th annual meet-\\ning of the association for computational linguistics: Hu-\\nman language technologies , pages 142–150.\\nMao, C., Jiang, L., Dehghani, M., V ondrick, C., Suk-\\nthankar, R., and Essa, I. (2021). Discrete representa-\\ntions strengthen vision transformer robustness. In Inter-\\nnational Conference on Learning Representations .\\nMeng, K., Bau, D., Andonian, A., and Belinkov, Y .\\n(2022). Locating and editing factual associations in\\ngpt. Advances in Neural Information Processing Sys-\\ntems, 35:17359–17372.\\nMiglani, V ., Yang, A., Markosyan, A., Garcia-Olano, D.,\\nand Kokhlikyan, N. (2023). Using captum to explain\\ngenerative language models. In Proceedings of the\\n3rd Workshop for Natural Language Processing Open\\nSource Software (NLP-OSS 2023) , pages 165–173.\\nMontavon, G., Binder, A., Lapuschkin, S., Samek, W., and\\nM¨uller, K.-R. (2019). Layer-wise relevance propagation:\\nan overview. Explainable AI: interpreting, explaining\\nand visualizing deep learning , pages 193–209.\\nMontavon, G., Lapuschkin, S., Binder, A., Samek, W., and\\nM¨uller, K.-R. (2017). Explaining nonlinear classifica-\\ntion decisions with deep taylor decomposition. Pattern\\nrecognition , 65:211–222.\\nNguyen, A., Dosovitskiy, A., Yosinski, J., Brox, T., and\\nClune, J. (2016). Synthesizing the preferred inputs for\\nneurons in neural networks via deep generator networks.\\nAdvances in neural information processing systems , 29.\\nPahde, F., Yolcu, G. ¨U., Binder, A., Samek, W., and La-\\npuschkin, S. (2023). Optimizing explanations by net-\\nwork canonization and hyperparameter search. In Pro-\\nceedings of the IEEE/CVF Conference on Computer Vi-\\nsion and Pattern Recognition , pages 3818–3827.\\nPaszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J.,\\nChanan, G., Killeen, T., Lin, Z., Gimelshein, N., Antiga,\\nL., et al. (2019). Pytorch: An imperative style, high-\\nperformance deep learning library. Advances in Neural\\nInformation Processing Systems , 32.\\nRadford, A., Jozefowicz, R., and Sutskever, I. (2017).\\nLearning to generate reviews and discovering sentiment.\\narXiv preprint arXiv:1704.01444 .\\nRajpurkar, P., Jia, R., and Liang, P. (2018). Know what you\\ndon’t know: Unanswerable questions for squad. In Pro-\\nceedings of the 56th Annual Meeting of the Association\\nfor Computational Linguistics (Volume 2: Short Papers) ,\\npages 784–789.Ribeiro, M. T., Singh, S., and Guestrin, C. (2016). ”why\\nshould I trust you?”: Explaining the predictions of any\\nclassifier. In Proceedings of the 22nd ACM SIGKDD\\nInternational Conference on Knowledge Discovery and\\nData Mining , pages 1135–1144. ACM.\\nSamek, W., Binder, A., Montavon, G., Lapuschkin, S.,\\nand M ¨uller, K.-R. (2017). Evaluating the visualiza-\\ntion of what a deep neural network has learned. IEEE\\nTransactions on Neural Networks and Learning Systems ,\\n28(11):2660–2673.\\nScheepers, T. (2017). Improving the compositionality of\\nword embeddings. Master’s thesis, Universiteit van Am-\\nsterdam, Science Park 904, Amsterdam, Netherlands.\\nSelvaraju, R. R., Cogswell, M., Das, A., Vedantam, R.,\\nParikh, D., and Batra, D. (2017). Grad-cam: Visual ex-\\nplanations from deep networks via gradient-based local-\\nization. In Proceedings of the IEEE International Con-\\nference on Computer Vision (ICCV) , pages 618–626.\\nShaham, U., Ivgi, M., Efrat, A., Berant, J., and Levy, O.\\n(2023). Zeroscrolls: A zero-shot benchmark for long\\ntext understanding. arXiv preprint arXiv:2305.14196 .\\nShrikumar, A., Greenside, P., and Kundaje, A. (2017).\\nLearning important features through propagating acti-\\nvation differences. In International Conference on Ma-\\nchine Learning , pages 3145–3153. PMLR.\\nSimonyan, K., Vedaldi, A., and Zisserman, A. (2014).\\nDeep inside convolutional networks: visualising image\\nclassification models and saliency maps. In Proceedings\\nof the International Conference on Learning Represen-\\ntations (ICLR) . ICLR.\\nSmilkov, D., Thorat, N., Kim, B., Vi ´egas, F., and Watten-\\nberg, M. (2017). Smoothgrad: removing noise by adding\\nnoise. arXiv preprint arXiv:1706.03825 .\\nSundararajan, M., Taly, A., and Yan, Q. (2017). Axiomatic\\nattribution for deep networks. In International Confer-\\nence on Machine Learning , pages 3319–3328. PMLR.\\nTouvron, H., Martin, L., Stone, K., Albert, P., Alma-\\nhairi, A., Babaei, Y ., Bashlykov, N., Batra, S., Bhar-\\ngava, P., Bhosale, S., et al. (2023). Llama 2: Open\\nfoundation and fine-tuned chat models. arXiv preprint\\narXiv:2307.09288 .\\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones,\\nL., Gomez, A. N., Kaiser, Ł., and Polosukhin, I. (2017).\\nAttention is all you need. Advances in Neural Informa-\\ntion Processing Systems , 30.\\nV oita, E., Ferrando, J., and Nalmpantis, C. (2023). Neu-\\nrons in large language models: Dead, n-gram, positional.\\narXiv preprint arXiv:2309.04827 .\\n11', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d485a5b9-f98f-48a2-b883-7faab6ec9a0d', embedding=None, metadata={'page_label': '12', 'file_name': '2402.05602v1.pdf', 'file_path': '/Users/iyaja/Git/llama-fs/sample_data/2402.05602v1.pdf', 'file_type': 'application/pdf', 'file_size': 14982917, 'creation_date': '2024-05-11', 'last_modified_date': '2024-05-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='V oita, E., Sennrich, R., and Titov, I. (2021). Analyzing the\\nsource and target contributions to predictions in neural\\nmachine translation. In 59th Annual Meeting of the As-\\nsociation for Computational Linguistics and the 11th In-\\nternational Joint Conference on Natural Language Pro-\\ncessing, ACL/IJCNLP , pages 1126–1140.\\nWiegreffe, S. and Pinter, Y . (2019). Attention is not not\\nexplanation. In Proceedings of the 2019 Conference on\\nEmpirical Methods in Natural Language Processing and\\nthe 9th International Joint Conference on Natural Lan-\\nguage Processing (EMNLP-IJCNLP) , pages 11–20.\\nWikimedia Foundation (2023. Accessed on Dec 01, 2023).\\nWikimedia downloads. https://dumps.wikimedia.org.\\nWolf, T., Debut, L., Sanh, V ., Chaumond, J., Delangue,\\nC., Moi, A., Cistac, P., Rault, T., Louf, R., Funtowicz,\\nM., et al. (2019). Huggingface’s transformers: State-\\nof-the-art natural language processing. arXiv preprint\\narXiv:1910.03771 .\\nZeiler, M. D. and Fergus, R. (2014). Visualizing and un-\\nderstanding convolutional networks. In European Con-\\nference Computer Vision - ECCV 2014 , pages 818–833.\\nZhang, B. and Sennrich, R. (2019). Root mean square layer\\nnormalization. Advances in Neural Information Process-\\ning Systems , 32.Appendix\\nA. Appendix I: Methodological Details\\nThis appendix provides further details on the methods pre-\\nsented in the paper. In particular, we focus on the At-\\ntnLRP method and provide implementation details and dis-\\ncuss the stability of the bias term and the noise problem\\nin Vision Transformers. Finally, we provide proofs for the\\nfour propositions presented in the main paper.\\nA.1. Details on Baseline Methods\\nIn the following, we present an overview of the baseline\\nmethods and their hyperparamter choices.\\nA.1.1. I NPUT×GRADIENT\\nGradients are one of the most straightforward approaches\\nto depict how sensitive the trained model is with respect\\nto each individual given feature (traditionally of the input\\nspace). By weighting the gradient with the input features,\\nthe model is locally linearized (Simonyan et al., 2014):\\nI×G(x)=∂fc(x)\\n∂x×x (20)\\nDue to the gradient shattering effect (Balduzzi et al., 2017)\\nwhich is a known phenomenon (especially in the ReLU-\\nbased CNNs), heatmaps generated by I ×G are very noisy,\\nmaking them in many cases not meaningful.\\nA.1.2. I NTEGRATED GRADIENTS\\nTo tackle the noisiness of I ×G, the idea to integrate gradi-\\nents along a trajectory has been proposed. Here, the gra-\\ndients of different ( m) interpolated versions of the input x,\\nnoted by x′, are integrated as (Sundararajan et al., 2017):\\nIG(x) = ( x−x′)Z1\\nα=0∂fj(x′+α×(x−x′))\\n∂xdx\\n≈(x−x′)mX\\nk=1∂fj(x′+k\\nm×(x−x′))\\n∂x×1\\nm\\n(21)\\nA.1.3. S MOOTH GRAD\\nA different technique towards the reduction of noisy gra-\\ndients is smoothing the gradients (Smilkov et al., 2017)\\nthrough generating ( m) various samples in the neighbor-\\nhood of input xasxε=x+N(µ, σ2)and computing the\\naverage of all gradients:\\nSmoothGrad (x) =1\\nmmX\\n1∂fj(xε)\\n∂xε(22)\\nIn this work, we set µ= 0 and perform a hyperparameter\\nsearch for σto find the optimal parameter.\\n12', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='96c5f9a2-9e6c-48f3-a24e-0c4081279121', embedding=None, metadata={'page_label': '13', 'file_name': '2402.05602v1.pdf', 'file_path': '/Users/iyaja/Git/llama-fs/sample_data/2402.05602v1.pdf', 'file_type': 'application/pdf', 'file_size': 14982917, 'creation_date': '2024-05-11', 'last_modified_date': '2024-05-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='A.1.4. A TTENTION ROLLOUT\\nSelf-Attention rollout (Abnar and Zuidema, 2020) capital-\\nizes on the intrinsic nature of the attention weights matrix\\nas a representative measure of token importance. It gener-\\nates a q×kmatrix where each row is normalized to form\\na probability distribution, representing the importance of\\neach query token to all key tokens. To compute the rele-\\nvance of hidden layer tokens ( h) to the original input to-\\nkens ( i), an iterative multiplication of the attention matri-\\nces on the left side is sufficient. To account for the residual\\nconnection through which the information of the previous\\ntokens flows, an identity matrix Iis added:\\nRh,i\\nk= (I+Ah,h)·Rh,i\\nk−1(23)\\nwhere k= 0 corresponds to the input layer and Rh,i\\n−1is\\ninitialized with the identity matrix I,hdenotes the hidden\\nfeature space, and istands for input dimension.\\n(Chefer et al., 2021a) build upon self-attention rollout and\\nweights the attention matrix with the gradient. Addition-\\nally, the weighted attention map is denoised by computing\\nthe mean value of only positive values.\\n¯A=Eb((∇A⊙A)+)\\nwhere Ebdenotes the expectation along the head dimen-\\nsion of the attention map. ¯Areplaces Ah,hin (23). For\\nencoder-decoder models, (Chefer et al., 2021a) present sev-\\neral additional considerations that are not mentioned here\\nfor brevity.\\n(Gildenblat, 2023) notes, that the rollout attributions can\\nfurther be improved by discarding outlier values. For that,\\nwe define a discard threshold dt∈[0,1]used to compute\\nthe quantile Q(dt), where dtrepresents the proportion of\\nthe data below the quantile e.g. with cumulative distribution\\nfunction P(¯A≤Q(dt)) =dt.\\n¯Am,n=(\\n0 if¯Am,n> Q(dt)\\n¯Am,n otherwise\\nA.1.5. A TMAN\\nAtMan (Deb et al., 2023) perturbs the pre-softmax activa-\\ntions along the k-dimension:\\nH=Q·KT\\n˜H=H⊙(1−pi)\\nwhere H∈Rb×q×k, and 1∈[1]b×q×ka matrix containing\\nonly 1. pidenotes a matrix ∈Rb×q×kwith\\npi\\nlmn=(\\npforn=i\\n0forn̸=iThus, for a single token i∈ {1,2, ..., N}, we suppress all\\nvalues along the column/key-dimension with a suppression\\nfactor p. The suppression factor is a hyperparameter that\\nmust be tuned to the dataset and model. For ViTs, addi-\\ntional cosine similarities are computed to suppress corre-\\nlated tokens as detailed in (Deb et al., 2023). For that, an\\nadditional hyperparameter denoted as tfor threshold must\\nbe optimized in ViTs only.\\nA.2. Details on AttnLRP\\nThis section provides more details on AttnLRP and justifies\\nthe specific parameter choices made in our work ( e.g., use\\nofγ-LRP in Vision Transformers).\\nA.2.1. C ONSERVATION & N UMERICAL STABILITY OF\\nBIASTERMS\\nThe relevance of a specific neuron or function, denoted as\\nRj, is computed by summing the contributions of the input\\nvariables, represented by Jjixi, and adding the contribu-\\ntion of the bias term, represented by ˜bj.\\nRj= X\\niJjixi+˜bj!\\nRj\\nfj(x)\\nThe relevance of the bias term itself, denoted as Rb, is cal-\\nculated as:\\nRb=˜bjRj\\nfj(x)\\nIf we want to compute the relevance of the input vari-\\nables Riwhile ensuring strict adherence to the conserva-\\ntion property (3), we must exclude the bias term, so that it\\ndoes not absorb part of the relevance Rb. There are three\\noptions: We can either completely omit the bias term, dis-\\ntribute its relevance value uniformly across the input vari-\\nables, or apply the identity rule.\\nOmitting the bias term : In this case, the relevance propaga-\\ntion equation is:\\nRi=X\\njRi←j=X\\njJjixiRjP\\niJjixi+ε\\nHere, we no longer divide by the original function fj(x).\\nHowever, it is important to ensure that no sign flips occur,\\nasP\\niJjiximight have a different sign than fj(x).\\nDistributing the bias term : Alternatively, we can distribute\\nthe relevance value of the bias term uniformly across the\\ninput variables. The relevance propagation equation in this\\ncase is:\\nRi=X\\njRi←j=X\\nj \\nJjixi+˜bj\\nN!\\nRj\\nfj(x) +ε\\n13', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='0874bd40-bc7e-4975-823f-9bcf4faca653', embedding=None, metadata={'page_label': '14', 'file_name': '2402.05602v1.pdf', 'file_path': '/Users/iyaja/Git/llama-fs/sample_data/2402.05602v1.pdf', 'file_type': 'application/pdf', 'file_size': 14982917, 'creation_date': '2024-05-11', 'last_modified_date': '2024-05-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Here, Nrepresents the number of input variables and Rb=\\n0. However, this approach may lead to numerical instabil-\\nities if the function fj(x) = 0 withxi= 0. Then, the\\nrelevance message Ri←jis:\\nRi←j=˜bj\\nNRj\\nε\\nSince εis very small, this term explodes and causes nu-\\nmerical instabilities. Thus, functions that fulfill f(0) = 0\\nshould preferably linearized such that the bias term does\\nnot cause numerical instabilities.\\nApplying the identity rule : We can apply the identity rule\\nas follows:\\nRl−1\\ni=Rl\\ni\\nHowever, we may encounter numerical instabilities, but\\nthese effects will only become visible in the next sequen-\\ntial propagation rule, not at this layer yet. For example in\\nthe softmax function, we may encounter a situation where\\naxl−1\\ni= 0 butfl\\ni(x)>0. If a non-zero relevance value\\nfrom layer lis assigned to fl\\ni(x), then its relevance value\\nis propagated through the identity rule to xl−1\\ni. Assuming\\nwe apply the ε-rule after the identity rule, the relevance is\\ngiven by:\\nR(l−2,l−1)\\nk←i=Jikxl−2\\nkRl−1\\ni\\n0 +ε\\nNote, that we divide by xl−1\\ni=fl−1\\ni= 0, which results in\\nnumerical instabilities. Further note, that these instabilities\\nwould not occur if xl−2\\nk= 0 orRl−1\\ni= 0, which is the\\ncase for a function fulfilling fl\\ni(0) = 0 .\\nIn summary, omitting the bias term completely, distributing\\nits relevance value uniformly across the input variables or\\napplying the identity rule are possible approaches, but they\\nhave their considerations and potential challenges. Regard-\\ning the softmax non-linearity, (V oita et al., 2021) distributes\\nthe bias term equally on all input variables, while (Ding\\net al., 2017; Chefer et al., 2021b) apply the element-wise\\nidentity rule (9). Both variants can lead in this case to se-\\nvere numerical instabilities.\\nA.2.2. H IGHLIGHTING THE DIFFERENCE BETWEEN\\nVARIOUS LRP METHODS\\nIn Table 3, we illustrate the different strategies employed\\nfor LRP in the past.\\nAs discussed in Appendix A.2.1, distributing the bias term\\nuniformly or applying the identity rule on the softmax func-\\ntion can lead to numerical instabilities that we also ob-\\nserved in our experiments.\\nApplying the ε-rule on bi-linear matrix multiplication does\\nviolate the conservation property (3) as proved in Lemma\\n3 of Chefer et al. (2021b). As a heuristic, (Chefer et al.,2021b) applies a normalization step by dividing both argu-\\nments by the summation of its absolute values.\\n(Ali et al., 2022) regards the softmax output as constant\\nand does not propagate relevance through it. This way, the\\nmatrix multiplication is not bi-linear anymore, but becomes\\nlinear, resulting in the attribution of only the value path.\\nConsequently, the query and key matrices can no longer be\\nattributed, which reduces the faithfulness and makes latent\\nexplanations in query and key matrices infeasible.\\nIn Figure 5, we illustrate different attribution maps for\\nall four options to handle the softmax function. The\\ngiven section is from the Wikipedia article on Mount\\nEverest. The model is expected to provide the next answer\\ntoken for the question ‘How high did they climb\\nin 1922? According to the text, the\\n1922 expedition reached 8,’ . For the correctly\\npredicted token 3is the attribution computed.\\nWhile the relevance values for AttnLRP or CP-LRP are be-\\ntween [−4,4], distributing the bias uniformely on the input\\nvariables or applying the identity rule leads to an explo-\\nsion of the relevances between [−1015,1015]. As a con-\\nsequence, the heatmaps resemble random noise. AttnLRP\\nhighlights the correct token the strongest, while CP-LRP\\nfocuses strongly on the start-of-sequence <s> token and\\nexhibits more background noise e.g. irrelevant tokens such\\nas ‘Context’, ‘attracts’, ‘Everest’ are highlighted, while At-\\ntnLRP does not highlight them or assigns negative rele-\\nvance. In Appendix B.5, we compare also other baseline\\nmethods. Note, that the model attends to numerous tokens\\nwithin the text which enables it to derive conclusions. Con-\\nsequently, an attribution that reflects the model behavior\\nwill highlight more than just the single accurate answer to-\\nken. The faithfulness experiments in Table 1 demonstrate,\\nthe AttnLRP captures the model reasoning most accurately.\\nA.2.3. T ACKLING NOISE IN VISION TRANSFORMERS\\nSince backpropagation-based attributions utilize the gradi-\\nent, they may produce noisy attributions in models with\\nmany layers, where gradient shattering and noisy gradients\\nappear (Balduzzi et al., 2017; Dombrowski et al., 2022).\\nHence, various adaptions of the ε-LRP rule were devel-\\noped to strengthen the signal-to-noise ratio by dampen-\\ning counter-acting activations (Bach et al., 2015; Montavon\\net al., 2019). Here, we use the generalized γ-rule that en-\\ncompasses all other proposed rules in the literature (Mon-\\ntavon et al., 2019). Let zijbe the contribution of input ito\\noutput j,e.g.Wjixi, and zjthe neuron output activation.\\nThen depending on the sign of zj:\\nR(l, l+1)\\ni←j=\\uf8f1\\n\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f3zij+γz+\\nij\\nzj+γP\\nkz+\\nkjRl+1\\nj ifzj>0\\nzij+γz−\\nij\\nzj+γP\\nkz−\\nkjRl+1\\nj else(24)\\n14', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='baa5fecc-3d9d-4633-8bd0-cd939e4a0e11', embedding=None, metadata={'page_label': '15', 'file_name': '2402.05602v1.pdf', 'file_path': '/Users/iyaja/Git/llama-fs/sample_data/2402.05602v1.pdf', 'file_type': 'application/pdf', 'file_size': 14982917, 'creation_date': '2024-05-11', 'last_modified_date': '2024-05-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Table 3. Conceptual differences between various-LRP methods and their implications.\\nMethods Softmax Matrix Multiplication Layer Normalization\\n(Ding et al., 2017) Identity rule ε-LRP not available\\n⇒unstable (Appendix A.2.1) ⇒violates conservation\\n(V oita et al., 2021) Taylor Decomposition at x ε-LRP Taylor Decomposition at x\\n(distributes the bias uniformly) (distributes the bias uniformly)\\n⇒unstable (Appendix A.2.1) ⇒violates conservation ⇒unstable (Appendix A.2.1)\\n(Chefer et al., 2021b) Identity rule ε-LRP Identity rule\\n⇒unstable (Appendix A.2.1) (with absolute normalization)\\n(Ali et al., 2022) Regarded as constant ε-LRP Identity rule\\n⇒No attribution (ensures conservation)\\ninside attention module\\nAttnLRP Taylor Decomposition at x ε-LRP Identity rule\\n(with bias) & uniform rule\\n(ensures conservation)\\nwithγ∈R>0,(·)+=max(·,0)and(·)−=min(·,0).\\nIfγ=∞, it will then be equivalent to the LRP- z+-rule,\\nwhich is given as\\nR(l, l+1)\\ni←j=(wijxi)+\\nz+\\njRl+1\\nj (25)\\nby only taking into account positive contributions z+\\nj=P\\ni(wijxi)+with(·)+= max(0 ,·). This is the case of\\nsoftmax layers (of the attention layer) where only positive\\nvalues are dealt with.\\nRemarkably, our observations reveal that attributions in\\nLLMs demonstrate high sparsity and lack visible noise,\\nwhile ViTs are susceptible to gradient shattering. We hy-\\npothesize that the discrete nature of the text domain may\\naffect robustness (Mao et al., 2021). Therefore, we only ap-\\nply the γ-rule in ViTs in the convolutional and linear FFN\\nlayers outside the attention module. To further increase the\\nfaithfulness, the γ-rule can be also applied on softmax lay-\\ners. Since the output of the softmax is always greater than\\nzero, we apply the simplified z+-rule (special case of γ-\\nrule).\\nA.3. Proofs\\nIn the following, we provide proofs for the rules presented\\nin the main paper.\\nA.3.1. P ROPOSITION 3.1: D ECOMPOSING SOFTMAX\\nIn this subsection, we demonstrate the decomposition of\\nthe softmax function by linearizing (4) it at x. We begin\\nby considering the softmax function:\\nsj(x) =exj\\nP\\niexiThe derivative of the softmax has two cases, which depend\\non the output and input indices iandj:\\n∂sj\\n∂xi=(\\nsj(1−sj)fori=j\\n−sjsi fori̸=j\\nConsequently, a Taylor decomposition (4) yields:\\nfj(x) =sj \\nxj−X\\nisixi!\\n+˜bj\\nWe differentiate between two cases, namely (i) when we\\nattribute relevance from output jto input i̸=jand (ii)\\nwhen we attribute from output jto input i=j.\\nRi←j=(\\n(xi−sixi)Rl+1\\ni fori=j\\n−sixiRl+1\\nj fori̸=j\\nApplying equation (5), we obtain:\\nRl\\ni=X\\njRi←j=xi(Rl+1\\ni−siX\\njRl+1\\nj)\\nA.3.2. P ROPOSITION 3.2: D ECOMPOSING\\nMULTIPLICATION\\nThe aim in is subsection is to decompose the multiplication\\nofNinput variables.\\nfj(x) =NY\\nixi\\nWe start by performing a Taylor Decomposition (4), then\\nwe derive the same decomposition with Shapley.\\n15', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e42fda6a-e052-4218-96df-16304d7300cc', embedding=None, metadata={'page_label': '16', 'file_name': '2402.05602v1.pdf', 'file_path': '/Users/iyaja/Git/llama-fs/sample_data/2402.05602v1.pdf', 'file_type': 'application/pdf', 'file_size': 14982917, 'creation_date': '2024-05-11', 'last_modified_date': '2024-05-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Taylor Decomposition : The derivative is\\n∂fj\\n∂xi=NY\\nk̸=ixk\\nConsequently, a Taylor decomposition (4) at xyields\\nfj(x) =NX\\ni∂fj\\n∂xixi+˜bj=NNY\\nkxk+˜bj=Nfj(x) +˜bj\\nWe can either omit the bias term or equally distribute it\\non the input variables to strictly enforce the conservation\\nproperty (3). Here, we demonstrate how to distribute the\\nbias term uniformly.\\nRi←j= \\nfj+˜bj\\nN!\\nRj\\nNfj(x) +˜bj=1\\nNRj\\nFor omitting the bias term, repeat the proof with ˜bj= 0.\\nShapley : The Shapley value (Lundberg and Lee, 2017) is\\ndefined as:\\nϕi(f) =X\\nS⊆N\\ni/∈S|S|!(N− |S| −1)!\\nN!(f(S∪ {i})−f(S))\\n(26)\\nwhere ϕi(v)is the Shapley value of the feature iand value\\nfunction f.Ndenotes the set of all features, and Sdenotes\\na feature subset (coalition).\\nWith respect to multiplication, zero is the absorbing ele-\\nment. Hence, we choose zero as our baseline value, and\\nthe Shapley value function becomes:\\nf(S∪ {i}) =Y\\nkxk\\nf(S) = 0\\nf(S∪ {i})−f(S)) =Y\\nkxk\\nThe symmetry theorem (Fryer et al., 2021) of Shapley\\nstates that the contributions of two feature values iandl\\nshould be the same if they contribute equally to all possible\\ncoalitions\\nf(S∪ {i}) =f(S∪ {l})\\n∀S⊆ {1,2, ...N}\\\\{i, l}\\nthenϕi(f) =ϕl(f). In addition, the efficiency theorem\\n(Fryer et al., 2021) states that the output contribution is\\ndistributed equally amongst all features. Hence, the out-\\nput contribution is equal to the sum of coalition values of\\nall features i,X\\niϕi(f) =f(N)Both theorems are applicable and hence it follows:\\nϕi(f) =1\\nNf(N)\\nIn the case of LRP, we identify f(N)asRj.\\nA.3.3. P ROPOSITION 3.3: D ECOMPOSING BI -LINEAR\\nMATRIX MULTIPLICATION\\nConsider the equation for matrix multiplication, where we\\ntreat the terms as single input variables:\\nOjp=X\\ni(AjiVip)\\nIn this case, the function already is in the form of an addi-\\ntive decomposition (1). Therefore,\\nRjip(Aji,Vip) =AjiVipRjp\\nOjp\\nNext, we decompose the individual terms using the derived\\nrule from the previous Section A.3.2\\nRji=X\\npRji←jip=X\\np1\\n2Rjip=X\\npAjiVipRjp\\n2Ojp\\nThe proof for Vipfollows a similar approach.\\nA.3.4. P ROPOSITION 3.4: L AYER NORMALIZATION\\nConsider layer normalization of the form\\nfj(x) =xj\\ng(x)\\nwhere g(x) =p\\nVar[x] +εorg(x) =q\\n1\\nNP\\nkx2\\nk+ε.\\nThe derivative is\\n∂fj\\n∂xi=1\\ng(x)2(\\ng(x)−xj∂g(x)\\n∂xifori=j\\n−xj∂g(x)\\n∂xifori̸=j(27)\\nIn LayerNorm (Ba et al., 2016), we assume for simplicity\\nE[x] = 0 , then the partial derivative simplifies to\\nV[x] =E[x2]−E[x]2=E[x2]\\n∂V[x]\\n∂xi=2\\nNxi\\nFurther, the partial derivative of RMSNorm (Zhang and\\nSennrich, 2019) is\\n∂RMSNorm\\n∂xi=xip\\nNP\\nkxk\\nAt reference point ˜xi= 0, the diagonal elements in equa-\\ntion (27) i̸=jare zero, yielding the Taylor decomposition:\\nfj(x) =∂fi\\n∂xi\\x0c\\x0c\\x0c\\n˜xi=0xi+˜bj=xi\\nε+˜bj\\n16', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='fcdded7f-e299-4511-ae8f-7673c5d20901', embedding=None, metadata={'page_label': '17', 'file_name': '2402.05602v1.pdf', 'file_path': '/Users/iyaja/Git/llama-fs/sample_data/2402.05602v1.pdf', 'file_type': 'application/pdf', 'file_size': 14982917, 'creation_date': '2024-05-11', 'last_modified_date': '2024-05-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='To enforce a strict notion of the conservation property (3),\\nthe bias term ˜bjcan be excluded or evenly distributed\\nacross the input variables. Because we have only a single\\ninput variable, the bias can be considered as part of xi.\\nRi=\\x10xi\\nε+˜bj\\x11Rj\\nxi\\nε+˜bj(28)\\nSince there is only one input variable and one output, the\\ndecomposition is equivalent to the identity function, as dis-\\ncussed in the Section 3.2.2 about component-wise non-\\nlinearities. Thus, we conclude that the identity rule applies\\nin this case.\\nRl−1\\ni=Rl\\ni (29)\\nNote, that this rule is numerically stable because fj(0) = 0\\nas discussed in Section A.2.1.B. Appendix II: Experimental Details\\nIn the following sections, we provide additional details\\nabout the experiments performed.\\nB.1. Models and Datasets\\nFor ImageNet faithfulness, we utilized the pretrained Vi-\\nsion Transformer 16-B weights of the PyTorch model\\nzoo (Paszke et al., 2019). We randomly selected 3200 sam-\\nples such that the standard error of mean converges to be-\\nlow 1% of the mean value.\\nFor Wikipedia, SQuAD v2 and IMDB faithfulness, we\\nevaluated the pretrained Llama 2-7b and Flan-T5 weights\\nhosted on huggingface (Wolf et al., 2019) on 4000 ran-\\ndomly selected validation dataset samples (fixed set for all\\nbaselines). Both models are casted to the Brain Floating\\nPoint (BFLOAT16) half-precision format to save memory\\nconsumption and to simulate real-world scenarios. Fur-\\nther, for Wikipedia next word prediction we evaluated the\\nmodel on a context size of 512 (from beginning of article\\nuntil context length is reached), while the context size in\\nSQuAD v2 varies between 169 to 4060. Although Flan-T5\\nwas trained on a smaller context size of 2000 tokens, the\\nrelative positional encoding allows it to handle longer con-\\ntext sizes with at least 8192 tokens (Shaham et al., 2023).\\nAdditionally for SQuAD v2 faithfulness and IoU, we uti-\\nlized the following prompt:\\nContext: [text of dataset sample]\\nQuestion: [question of dataset sample]\\nAnswer:\\nIn order to prevent out-of-distribution samples, we\\nonly perturb the tokens inside the context [text of\\ndataset sample] . Since the length of the SQuAD v2\\nquestions varies and the length of the validation dataset is\\nsmall, the standard error of mean is higher in Table 1.\\nFor IMDB, we added a last linear layer to Llama 2-7b and\\nfinetuned the model, which achieves 93% accuracy on the\\nvalidation dataset.\\nIf we encountered NaN values for a sample, we removed it\\nfrom the evaluation. This happened for Grad ×AttnRollout\\nand AtMan in the Wikipedia dataset. However, the standard\\nerror of the mean remains small, as can be seen in Table 1.\\nB.2. Input Perturbation Metrics\\nIn the following, we summarize the perturbation process\\nintroduced by (Samek et al., 2017) in a condensed manner.\\nGiven an attributions map Rl\\ni(xi)per input features x=\\n{xi}N\\ni=1in layer l.Hdenotes a set of relevance values for\\nall input features xi:\\nH= (R0\\n0(x0), R0\\n1(x1), ..., R0\\nN−1(xN−1)) (30)\\n17', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a980263f-6b92-46d7-9bcb-5ab41d1a3aac', embedding=None, metadata={'page_label': '18', 'file_name': '2402.05602v1.pdf', 'file_path': '/Users/iyaja/Git/llama-fs/sample_data/2402.05602v1.pdf', 'file_type': 'application/pdf', 'file_size': 14982917, 'creation_date': '2024-05-11', 'last_modified_date': '2024-05-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Then, the flipping perturbation process iteratively substi-\\ntutes input features with a baseline value b∈RN(the\\nbaseline might be zero, noise generated from a Gaussian\\ndistribution, or pixels of a black image in the vision task).\\nAnother reverse equivalent variant, referred as insertion ,\\nbegins with a baseline band reconstructs the input xstep-\\nwise. The function performing the perturbation is denoted\\nbygFfor flipping and gIfor insertion. The perturbation\\nprocedure is either conducted in a MoRF (Most Relevant\\nFirst) or LeRF (Least Relevant First) manner based on the\\nsorted members of H. Regardless of the replacement func-\\ntion, the MoRF and LeRF perturbation processes can be\\ndefined as recursive formulas at step k={0,1, ..., N −1}:\\nMoRF Pert. Process =\\uf8f1\\n\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f3x0\\nMoRF =x\\nxk\\nMoRF =g(F|I)(xk−1\\nMoRF ,b)\\nxN−1\\nMoRF =b\\nwhere xk\\nMoRF denotes the perturbed input feature xat step\\nkin MoRF process.\\nLeRF Pert. Process =\\uf8f1\\n\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f3x0\\nLeRF =b\\nxk\\nLeRF =g(F|I)(xk−1\\nLeRF ,b)\\nxN−1\\nLeRF =x\\nwhere xk\\nLeRF denotes the perturbed input feature xat step\\nkin LeRF process.\\nResults of these processes are perturbed input sets of\\nXF\\nMoRF = (x0\\nMoRF ,x1\\nMoRF , ...,xN−1\\nMoRF )andXF\\nLeRF =\\n(x0\\nLeRF ,x1\\nLeRF , ...,xN−1\\nLeRF ). It is notable that by using gI,\\nXI\\nLeRF =XF\\nMoRF and vice versa. By feeding these sets\\nto the model and computing the corresponding logit output\\nfj, a curve will be induced and consequently the area under\\nthe curve can be calculated:\\nAF\\nMoRF =AI\\nLeRF =1\\nNN−1X\\nk=0fj(xk\\nMoRF ) (31)\\nwhere xk\\nMoRF ∈ XF\\nMoRF orxk\\nMoRF ∈ XI\\nLeRF .\\nBy using XI\\nMoRF ,AI\\nMoRF =AF\\nLeRF can be computed\\nsimilarly. A faithful explainer results in a low value of\\nAF\\nMoRF orAI\\nLeRF . Further, a faithful explainer is expected\\nto have large AF\\nLeRF orAI\\nMoRF values.\\nUltimately to reduce introducing out-of-distribution ma-\\nnipulations and the sensitivity towards the chosen baseline\\nvalue, the work of (Bl ¨ucher et al., 2024) proposes to lever-\\nage both insights and to obtain a robust measure as\\n∆AF=AF\\nLeRF−AF\\nMoRF\\n∆AI=AI\\nMoRF −AI\\nLeRFwhere a higher score signifies a more faithful explainer.\\nWe performed all faithfulness perturbations with a baseline\\nvalue of zero. In the case of LLMs, we aggreated the rele-\\nvance for each token and flipped the entire embedding vec-\\ntor of input tokens to the baseline value. For ViTs, we used\\nthe relevances of the input pixels and flipped input pixels\\nto the baseline value.\\nB.3. Hyperparameter search for Baselines\\nAs describes in Section A.1, several baseline attribu-\\ntion methods have hyperparameters that must be tuned\\nto the datasets. The hyperparameters of SmoothGrad\\n(σ∈[0.01,0.25]), AtMan (suppression value ∈[0.1,1.0]\\nand threshold ∈[0,1.0]), AttnRoll (discard threshold ∈\\n[0.90,1.00]), and G ×AttnRoll (discard threshold ∈\\n[0.90,1.00]) need to be optimized. The best searched hy-\\nperparameters according to the perturbation experiments\\nare available in the captions of Tables 5, 6, 7, 8.\\nB.4. LRP Composites for ViT\\nApplying the ε-rule on all linear layers inside LLMs is suf-\\nficient to obtain faithful and noise-free attributions. How-\\never, for the Vision Transformers, we apply the γ-rule on\\nall linear layers (including the convolutional layers) outside\\nthe attention module. Since the γ-rule has a hyperparame-\\nter, the work (Pahde et al., 2023) proposed to tune the pa-\\nrameter using a grid-search. This optimization search (or in\\nLRP known as composite search) is computational highly\\ndemanding.\\nThe Vision Transformer consists of many linear layers. Our\\nproposed approach is to use different γvalues across dif-\\nferent layer types. According to (Vaswani et al., 2017) the\\nattention module consists of several linear layers which we\\nrefer to as LinearInputProjection :\\nQ=WqX+bq\\nK=WkX+bk\\nV=WvX+bv\\nIn the attention layer, after the softmax (11), there exists\\nanother linear layer performing the output projection back\\ninto the residual stream, denoted as LinearOutputProjec-\\ntion:\\ny=WoO+bo\\nThe other layers in the whole network, will be referred to\\nasLinear .\\nThe perturbation experiment had been conducted over\\nthese layers using different types of rules including Ep-\\nsilon, ZPlus, Gamma, and AlphaBeta (with α= 2 and\\nβ= 1according to (Montavon et al., 2019)).\\n18', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='a14f39f3-2fe7-4b21-8719-c19fa3d691d5', embedding=None, metadata={'page_label': '19', 'file_name': '2402.05602v1.pdf', 'file_path': '/Users/iyaja/Git/llama-fs/sample_data/2402.05602v1.pdf', 'file_type': 'application/pdf', 'file_size': 14982917, 'creation_date': '2024-05-11', 'last_modified_date': '2024-05-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='0.0 0.2 0.4 0.6 0.8 1.002468AttnLRP, AUC=6.19 ±0.02\\nG×AttnRoll, AUC=2.60 ±0.03\\nAtMan, AUC=0.70 ±0.02\\nSmoothGrad, AUC=-0.04 ±0.03\\n0.0 0.2 0.4 0.6 0.8 1.002468AttnLRP, AUC=1.48 ±0.02\\nG×AttnRoll, AUC=4.01 ±0.03\\nAtMan, AUC=5.57 ±0.03\\nSmoothGrad, AUC=3.63 ±0.03\\n0.0 0.2 0.4 0.6 0.8 1.002468\\nAttnLRP, AUC=7.67 ±0.02\\nG×AttnRoll, AUC=6.22 ±0.02\\nAtMan, AUC=6.27 ±0.03\\nSmoothGrad, AUC=3.58 ±0.03\\nPerturbation Steps ( k)Logits (fj)\\nPerturbation Steps ( k)Logits (fj)\\nPerturbation Steps ( k)Logits (fj)\\nPerturbation Steps ( k)Logits (fj)Figure 4. Comparison of the AttnLRP (ours) with the γ-rule, Grad ×AttnRoll (Chefer et al., 2021a), AtMan (Deb et al., 2023), and\\nSmoothGrad (Smilkov et al., 2017) techniques through the perturbation experiment (faithfulness) on the ViT-B-16 using 3200 random\\nsamples of ImageNet. From left to right, the plots correspond to fj(XF\\nLeRF )−fj(XF\\nMoRF )(large area is good), fj(XF\\nMoRF )(steep\\ndecline is good), and fj(XF\\nLeRF )(slow decline is good). “AUC” denotes the Area under Curve.\\nThe most faithful composite, that we obtained for AttnLRP\\nand CP-LRP, is in Table 4. More details over the statistics\\nof the conducted experiments are available in Figures 12,\\n13, 14, 15, 16.\\nB.5. Attributions on SQuAD v2\\nIn Figure 7, we illustrate attributions for different state-of-\\nthe-art methods computed for the first token of the answer\\n(highlighted in red). The Flan-T5 model correctly predicts\\n182 million , where the first explained token is 18.\\nGradient-based methods such as G ×I, SmoothGrad, IG or\\nGrad-CAM are noisy and not really informative. While the\\nheatmaps of I ×G or Grad-CAM seem to be inverted, we\\nexperimented with inverting the attributions on a subset,\\nhowever we did not notice improvement and applied the\\nrules with their original definition. Grad ×Attn Rollout suf-\\nfers from background noise. AtMan produces highly sparse\\nattributions, assigning large positive relevance to the an-\\nswer token 18, however, also assigning a similar amount\\nof relevance to the token much , which is part of the ques-\\ntion. AttnLRP and CP-LRP identify the token 18as be-\\ning the most relevant token and also relate it (by assign-\\ning positive and negative relevance) to other information\\nin the text such as 27.7 ,132 oraverage . We con-\\njecture that such targeted contrasting reflects the reasoning\\nprocess of the model ( e.g., is necessary to distinguish be-\\ntween related questions about how many tons are blown\\nout vs. how many tons remain on the ground). A system-\\natic analysis of these effects remain an interesting topic for\\nfuture work. The similarity between AttnLRP and CP-LRP\\nin Flan-T5 are in line with the quantitative evaluation from\\nTable 1, which showed a small, but consistent advantage\\nof AttnLRP over CP-LRP wrt. faithfulness, while in Llama2, AttnLRP substantially outperforms. For comparison, we\\nalso visualize a random attribution with Gaussian noise.\\nB.6. Benchmarking Cost, Time and Memory\\nConsumption\\nWe benchmark the runtime and peak GPU memory con-\\nsumption for computing a single attribution for Llama\\n2 with batch size 1 on a node with four A100-SXM4\\n40GB, 512 GB CPU RAM and 32 AMD EPYC 73F3\\n3.5 GHz. Because AtMan, LRP and AttnRollout-variants\\nneed access to the attention weights, we did not use flash-\\nattention (Dao et al., 2022).\\nTo calculate energy cost, we assume a price of 0.16$ per\\nkWh of energy, and that a single A100 GPU consumes on\\naverage 130W. Figure 8 depicts the cost, the runtime and\\npeak GPU memory consumption. Since perturbation-based\\nmethods are memory efficient, a 70b model with full con-\\ntext size of 4096 is attributable. However, LRP with check-\\npointing requires more memory than a node can supply.\\nB.7. Attributions of Knowledge Neurons\\nFigure 9, 10 and 11 illustrate the top 10 sentences in\\nthe Wikipedia summary dataset that maximally activate a\\nknowledge neuron. We applied AttnLRP to highlight the\\ntokens inside these reference samples. We observe that\\nknowledge neurons exhibit remarkable disentanglement,\\ne.g., neuron #256 oflayer 18 shown in Figure 9 seems\\nto encode concepts related to transport systems (railways\\nin particular), while neuron #2207 oflayer 20 shown\\nin Figure 10 seems to encode the concept teacher, in par-\\nticular a teacher, in an unusual context ( e.g., inappropriate\\nbehavior, sexual misconduct). The degree of disentangle-\\n19', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='d8008838-9a54-4097-b49e-38a487d317e5', embedding=None, metadata={'page_label': '20', 'file_name': '2402.05602v1.pdf', 'file_path': '/Users/iyaja/Git/llama-fs/sample_data/2402.05602v1.pdf', 'file_type': 'application/pdf', 'file_size': 14982917, 'creation_date': '2024-05-11', 'last_modified_date': '2024-05-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Table 4. Proposed composite for the AttnLRP and CP-LRP methods used for the Vision Transformer.\\nLayer Type Rule Proposed\\nConvolution Gamma( γ= 0.25)\\nLinear Gamma( γ= 0.05)\\nLinearInputProjection Epsilon\\nLinearOutputProjection Epsilon\\nCP-LRP\\nSoftmax Distribute BiasAttnLRP\\nSoftmax Identity Rule\\nFigure 5. Comparison of four different LRP variants computed on a Llama 2-7b model. The given section is from the Wikipedia article\\non Mount Everest. The model is expected to provide the next answer token for the question ‘How high did they climb in\\n1922? According to the text, the 1922 expedition reached 8,’ . For the correctly predicted token 3is the\\nattribution computed. Distributing the bias uniformely on the input variables (Softmax Distribute Bias) or applying the identity rule\\n(Softmax Identity Rule) leads to numerical instabilities. AttnLRP highlights the correct token the strongest, while CP-LRP focuses\\nstrongly on the start-of-sequence <s> token and exhibits more background noise e.g. irrelevant tokens such as ‘Context’, ‘attracts’,\\n‘Everest’ are highlighted, while AttnLRP does not highlight them or assigns negative relevance.\\n20', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='15f65b11-6a04-4231-8033-0f799bae4715', embedding=None, metadata={'page_label': '21', 'file_name': '2402.05602v1.pdf', 'file_path': '/Users/iyaja/Git/llama-fs/sample_data/2402.05602v1.pdf', 'file_type': 'application/pdf', 'file_size': 14982917, 'creation_date': '2024-05-11', 'last_modified_date': '2024-05-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Original Image\\n I×G\\n IG\\n Smooth Grad\\n AttnRoll\\n G×AttnRoll\\n AtMan\\n CP-LRP (Ali et al.)\\n γCP-LRP\\n AttnLRP (ours)Figure 6. Explanation heatmaps of the methods used for the perturbation experiments on the Vision Transformer. A checkerboard effect\\nis visible for almost every method, especially in AttnRoll (Abnar and Zuidema, 2020), G ×AttnRoll (Chefer et al., 2021a), and AtMan\\n(Deb et al., 2023). We improve upon CP-LRP (Ali et al., 2022) by applying the γ-rule as described in B.4. While qualitatively CP-LRP\\n(with γextension for ViT) and AttnLRP give similar explanations, quantitative results in Table 1 show a consistent improvement of\\nAttnLRP over CP-LRP in terms of faithfulness. Moreover, the detailed investigation of the processes within the attention model can\\nbe investigated with AttnLRP only, while it is not possible with CP-LRP. We leave these further explorations for future work. The\\nquantitative experiments (faithfulness test) validate this observation, see Table 5.\\n21', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='da44b761-cdc9-4ca2-8e8a-88f2b7ac6ee7', embedding=None, metadata={'page_label': '22', 'file_name': '2402.05602v1.pdf', 'file_path': '/Users/iyaja/Git/llama-fs/sample_data/2402.05602v1.pdf', 'file_type': 'application/pdf', 'file_size': 14982917, 'creation_date': '2024-05-11', 'last_modified_date': '2024-05-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='AtMan\\nAttention RolloutGrad-weighted Attention RolloutAttnLRP\\nSmoothGradIntegrated GradientGradient x Input\\nGrad-CAM\\nRandomCP-LRPQuestion: How many tons of dust are blown out of the Sahara each year?\\nAnswer: 182 millionFigure 7. Evaluation on the SQuAD v2: We compute attributions for different state-of-the-art methods on the first token of the answer\\n(highlighted in red). Gradient-based methods such as G ×I, SmoothGrad, IG or Grad-CAM are noisy. Grad ×Attn Rollout suffers from\\nbackground noise. AtMan produces highly sparse attributions, assigning an equal amount of relevance to a token, which is part of the\\nquestion, as to token 18. CP-LRP has a different weighting of the tokens e.g. the word ‘much’ in the question is not highlighted by CP-\\nLRP, while AttnLRP highlights it stronger and AtMan focuses excessively on it. For comparison, we also visualize a random attribution\\nwith Gaussian noise.\\nment should be studied in future work.\\n22', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='28148a15-d890-4a2f-b623-2da915edada1', embedding=None, metadata={'page_label': '23', 'file_name': '2402.05602v1.pdf', 'file_path': '/Users/iyaja/Git/llama-fs/sample_data/2402.05602v1.pdf', 'file_type': 'application/pdf', 'file_size': 14982917, 'creation_date': '2024-05-11', 'last_modified_date': '2024-05-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Figure 8. From left to right: Cost in dollar, time in seconds and peak GPU memory in gigabytes for AttnLRP and linear-time perturbation.\\nEvaluated on Llama 2-70b and Llama 2-13b models on a node with four A100-SXM4 40GB. G ×AttnRollout is in the range of AttnLRP\\nand omitted for clarity of visualization. Because AttnLRP consumes more than 160 GB of RAM, the curves for the 70b model stop.\\nMeasured at fixed intervals of context size 32, 64, 128, 256, 512, 1024, 2048, 3000, 4096.\\nTable 5. ViT Perturbation Experiment (Faithfulness). For SmoothGrad, we set σ= 0.01, for AtMan p= 1.0andt= 0.1, for AttnRoll\\ndt= 0.99, and for G ×AttnRoll dt= 0.91. “all epsilon” indicates that the ε-rule has been used on the linear and convolutional layers.\\nThe term “best” refers to the utilization of LRP with the composite proposed in B.4. ∆AFdenotes the area under the curve for a\\nflipping perturbation experiment which leverages both AF\\nMoRF of the most relevant first order, and AF\\nLeRF of least relevant first order.\\n(∆AF=AF\\nLeRF−AF\\nMoRF ). As discussed in Section B.2, this is equivalent to insertion perturbation.\\nMethods ViT-B-16\\nImageNet\\n(↑)∆AF(↓)AF\\nMoRF (↑)AF\\nLeRF\\nRandom 0.01 4.71 4.71\\nI×G 0.90 2.78 3.69\\nIG 1.54 2.55 4.10\\nSmoothG -0.04 3.63 3.58\\nGradCAM 0.27 5.35 5.63\\nAttnRoll 1.31 4.866 6.17\\nG×AttnRoll 2.60 4.01 6.22\\nAtMan 0.70 5.57 6.27\\nCP-LRP (all epsilon) 2.53 2.45 4.98\\nγCP-LRP (best) 6.06 1.53 7.59\\nAttnLRP (all epsilon) 2.79 5.22 2.42\\nAttnLRP (best) 6.19 1.48 7.67\\n23', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='9db71f53-7805-441c-8d88-ae6dc0ff16a9', embedding=None, metadata={'page_label': '24', 'file_name': '2402.05602v1.pdf', 'file_path': '/Users/iyaja/Git/llama-fs/sample_data/2402.05602v1.pdf', 'file_type': 'application/pdf', 'file_size': 14982917, 'creation_date': '2024-05-11', 'last_modified_date': '2024-05-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Table 6. Wikipedia Perturbation Experiment (Faithfulness). For SmoothGrad, we set σ= 0.1, for AtMan p= 1.0, for AttnRoll dt= 1,\\nand for G ×AttnRoll dt= 1. ”all epsilon” indicates that the ε-rule has been used on all linear layers. ∆AIdenotes the area under\\nthe curve for the insertion perturbation experiment which leverages both AI\\nMoRF of the most relevant first order, and AI\\nLeRF of least\\nrelevant first order. ( ∆AI=AI\\nMoRF−AI\\nLeRF ). As discussed in Section B.2, this is equivalent to flipping perturbation.\\nMethods Llama 2-7b\\nWikipedia\\n(↑)∆AI(↑)AI\\nMoRF (↓)AI\\nLeRF\\nRandom -0.07 2.31 2.38\\nI×G 0.18 1.27 1.09\\nIG 4.05 3.74 -0.31\\nSmoothG -2.22 0.68 2.90\\nGradCAM 2.01 2.36 0.35\\nAttnRoll -3.49 1.46 4.95\\nG×AttnRoll 9.79 8.79 -1.00\\nAtMan 3.31 4.06 0.76\\nCP-LRP (all epsilon) 7.85 6.43 -1.42\\nAttnLRP (all epsilon) 10.93 9.08 -1.85\\nTable 7. IMDB Perturbation Experiment (Faithfulness), For SmoothGrad we set σ= 0.05, for AtMan p= 0.7, for AttnRoll dt= 1, and\\nfor G×AttnRoll dt= 1. ”all epsilon” indicates that the ε-rule has been used to propagate relevance to the layers. ∆AIdemonstrates\\nthe area under the curve for the perturbation experiment of the type Insertion which leverages insights from both AI\\nMoRF of the most\\nrelevant first order, and AI\\nLeRF of least relevant first order. ( ∆AI=AI\\nMoRF−AI\\nLeRF ). As discussed in Section B.2, this is equivalent\\ntoflipping perturbation.\\nMethods Llama 2-7b\\nIMDB\\n(↑)∆AI(↑)AI\\nMoRF (↓)AI\\nLeRF\\nRandom -0.01 -0.47 -0.46\\nI×G 0.12 -0.69 -0.81\\nIG 1.23 -0.06 -1.29\\nSmoothG 0.25 -0.74 -0.98\\nGradCAM -0.82 -1.10 -0.28\\nAttnRoll -0.64 -0.64 0.00\\nG×AttnRoll 1.61 0.77 -0.84\\nAtMan -0.05 -0.54 -0.49\\nCP-LRP (all epsilon) 1.72 0.50 -1.22\\nAttnLRP (all epsilon) 2.50 1.12 -1.38\\n24', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='4e3e7f7b-d16e-4db4-9238-3869fcf0a7eb', embedding=None, metadata={'page_label': '25', 'file_name': '2402.05602v1.pdf', 'file_path': '/Users/iyaja/Git/llama-fs/sample_data/2402.05602v1.pdf', 'file_type': 'application/pdf', 'file_size': 14982917, 'creation_date': '2024-05-11', 'last_modified_date': '2024-05-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Table 8. SQuAD v2 Perturbation Experiment (Faithfulness). For SmoothGrad, we set σ= 0.1and for AtMan p= 0.9, for AttnRoll\\ndt= 1, and for G ×AttnRoll dt= 1. ”all epsilon” indicates that the ε-rule has been used on all linear layers. ∆AIdenotes the area\\nunder the curve for the insertion perturbation experiment which leverages both AI\\nMoRF of the most relevant first order, and AI\\nLeRF of\\nleast relevant first order. ( ∆AI=AI\\nMoRF−AI\\nLeRF ). As discussed in Section B.2, this is equivalent to flipping perturbation.\\nMethods Flan-T5-XL\\nSQuAD v2\\n(↑)∆AI(↑)AI\\nMoRF (↓)AI\\nLeRF\\nRandom 0.01 -6.05 -6.06\\nI×G 0.27 -5.51 -5.78\\nIG 0.77 -5.31 -6.08\\nSmoothG 0.16 -5.47 -5.63\\nGradCAM 0.94 -5.24 -6.19\\nAttnRoll -0.42 -5.96 -5.54\\nG×AttnRoll -0.06 -5.65 -5.60\\nAtMan 1.01 -5.18 -6.19\\nCP-LRP (all epsilon) 1.74 -4.93 -6.67\\nAttnLRP (all epsilon) 1.76 -4.91 -6.67\\n25', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='19c62121-8783-412e-b4fd-901f0e8c3262', embedding=None, metadata={'page_label': '26', 'file_name': '2402.05602v1.pdf', 'file_path': '/Users/iyaja/Git/llama-fs/sample_data/2402.05602v1.pdf', 'file_type': 'application/pdf', 'file_size': 14982917, 'creation_date': '2024-05-11', 'last_modified_date': '2024-05-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Figure 9. AttnLRP attributions on top 10 ActMax sentences col-\\nlected over the Wikipedia summary dataset for neuron #256 , in\\nlayer 18 . The knowledge neuron seems to activate for trans-\\nport systems (railways in particular).\\nFigure 10. AttnLRP attributions on top 10 ActMax sentences col-\\nlected over the Wikipedia summary dataset for neuron #2207 , in\\nlayer 20 . The knowledge neuron is activating for ‘teacher’,\\nin unusual context such as inappropriate behavior, sexual miscon-\\nduct etc.\\nFigure 11. AttnLRP attributions on top 10 ActMax sentences col-\\nlected over the Wikipedia summary dataset for neuron #922 , in\\nlayer 18 . The knowledge neuron seems to be activating for\\nscientific descriptions of plants.\\nz+ϵ CP-LRP2.53.03.54.04.55.05.56.0(↑)∆AF\\nFigure 12. Statistics on Rules used for softmax layers: Either ap-\\nplying z+,ε-rule, or regarding as constant as proposed in CP-\\nLRP. Propagating relevance values through (specifically by ap-\\nplying z+rule) softmax improves the faithfulness of explanations\\ncompared to the case where we block its propagation.\\n26', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='bf3343d4-da35-47fb-8133-bfecc04ba3ac', embedding=None, metadata={'page_label': '27', 'file_name': '2402.05602v1.pdf', 'file_path': '/Users/iyaja/Git/llama-fs/sample_data/2402.05602v1.pdf', 'file_type': 'application/pdf', 'file_size': 14982917, 'creation_date': '2024-05-11', 'last_modified_date': '2024-05-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='AlphaBeta z+Gamma(γ= 0.05)Gamma(γ= 0.1)Gamma(γ= 0.25)2.53.03.54.04.55.05.56.0(↑)∆AFFigure 13. Statistics on Rules used for Convolution layers: Ap-\\nplying z+and AlphaBeta proposes acceptable results however the\\nmost faithful results can be reached via Gamma( γ= 0.25).\\nAlphaBeta z+Gamma(γ= 0.05)Gamma(γ= 0.1)Gamma(γ= 0.25)2.53.03.54.04.55.05.56.0(↑)∆AF\\nFigure 14. Statistics on Rules used for Linear layers: Similar to\\nConvolution layers, Gamma seams more promising however with\\ndifferent γvalue ( 0.05in this case).\\nz+ϵ Gamma(γ= 0.05)Gamma(γ= 0.1)Gamma(γ= 0.25)2.53.03.54.04.55.05.56.0(↑)∆AF\\nFigure 15. Statistics on Rules used for LinearInputProjection lay-\\ners: Gamma and ϵrules are competitive in this case, however\\nsince there is larger difference between the minimum and the\\nlower quartile in Gamma rules, the most faithful choice will be\\nϵ-rule.\\nϵ Gamma(γ= 0.05) Gamma(γ= 0.1) Gamma(γ= 0.25)2.53.03.54.04.55.05.56.0(↑)∆AFFigure 16. Statistics on Rules used for LinearOutputProjection\\nlayers: The ϵ-rule outperforms other rules clearly.\\n27', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " ImageDocument(id_='607ede18-31a9-4b36-96dc-29c360701770', embedding=None, metadata={'file_path': '/Users/iyaja/Git/llama-fs/sample_data/d20e3b9a-9981-41c4-a6f7-dc1bafff4761.JPG', 'file_name': 'd20e3b9a-9981-41c4-a6f7-dc1bafff4761.JPG', 'file_type': 'image/jpeg', 'file_size': 110049, 'creation_date': '2024-05-11', 'last_modified_date': '2024-05-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n', image=None, image_path='/Users/iyaja/Git/llama-fs/sample_data/d20e3b9a-9981-41c4-a6f7-dc1bafff4761.JPG', image_url=None, image_mimetype=None, text_embedding=None)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
